---
title: "Modelo Preditivo de Óbitos no Trânsito Brasileiro"
date: 2024-02-29

smooth-scroll: true

authors:
  - name: João Pedro Melani Saraiva
  - name: Pedro Augusto Borges dos Santos

description: "Modelo de aprendizado de máquina orientado a dados relacionados à segurança viária para o reconhecimento de padrões e previsão de óbitos no trânsito"

title-block-banner: true

format: 
  html:
    editor: visual
    dpi: 300
    number-sections: true
    mermaid: 
      theme: neutral

knitr: 
  opts_chunk: 
    fig.align: center

bibliography: references.bib
csl: associacao-brasileira-de-normas-tecnicas.csl
toc: true
toc-title: Sumário

lang: pt
---

```{r include=FALSE}
# packages
library(tidyverse)
library(gt)
library(forecast)
library(ggcorrplot)
library(onsvplot)
library(knitr)
library(here)
library(tidymodels)
library(kableExtra)
library(fleetbr)
library(roadtrafficdeaths)
library(plotly)
library(arrow)

# opções de display
theme_set(theme_onsv())
set.seed(123)

# load dos dados
load(here("data","tabela_total.rda"))
load(here("data","tabela_total_mensal.rda"))
load(here("data/pib_mensal.rda"))
load(here("data","tabela_condutores.rda"))
temp <- tempfile()
download.file("https://github.com/ONSV/prfdata/releases/download/v0.2.0/prf_sinistros.zip", temp)
unzip(temp, exdir = tempdir())
unlink(temp)
prf_sinistros <- open_dataset(paste(sep = "/", file.path(tempdir()), "prf_sinistros"))

# paleta
paleta = as_vector(unname(onsv_palette))

# supressão dos warnings
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Introdução

O presente cenário mundial acerca de mortes e lesões relacionadas à sinistros de trânsito posa sérios desafios à saúde pública global, e as tendências evidenciadas pelos dados atuais indicam que esta realidade deve perdurar pelo futuro próximo [@worldhealthorganization2023]. Sendo uma das causas de mortes mais comuns no mundo, as ocorrências de sinistros de trânsito afetam principalmente pedestres, ciclistas e motociclistas, além de induzir severos danos materiais, tanto em questão de propriedade particular quanto pública. Isto estimula países a buscarem métodos estimativos sobre os efeitos sociais, econômicos e epidemiológicos da taxa de mortes no trânsito e como se traduzem em custos e perdas na produtividade da sociedade em geral [@rodríguez2020].

A segurança viária pode ser um indicador da situação de desenvolvimento de uma região, visto que é uma característica do desempenho da mobilidade urbana. Entende-se que as mortes no trânsito dependem de diversos fatores estruturais, socioeconômicos e ambientais do contexto urbano [@zhong-xiang2014], o que implica que elevadas taxas de sinistros viários colaboram no diagnóstico de problemas da mobilidade e saúde pública em geral, despertando o debate político sobre a regulamentação das normas viárias e apontando a carência da sociedade em combater estes eventos.

Apesar da crescente adesão por itens de segurança veicular, os sinistros de trânsito permanecem como um problema de saúde pública, já que fazem parte de um agravo que repercute por toda a sociedade [@andrade2019], sendo a décima segunda maior causa de óbitos em todas as faixas etárias e a principal entre indivíduos de 5 a 29 anos [@worldhealthorganization2023]. Como previsto por modelos estatísticos prévios à 2020 [@blumenberg2018], o Brasil apresentou baixo desempenho em cumprir a meta estabelecida pela Primeira Década de Ações pela Segurança no Trânsito. Neste cenário, o Plano Nacional de Redução de Mortes e Lesões no Trânsito (PNATRANS) foi desenvolvido para guiar as ações pela mobilidade segura nacional durante o período da Segunda Década de Ação pela Segurança no Trânsito [@ministériodostransporte2018], na intenção de aprimorar o desempenho da segurança viária em relação a década passada, se alinhando aos Objetivos de Desenvolvimento Sustentável estabelecidos pela Agenda 2030 da Organização das Nações Unidas (ONU). Para atingir tais metas, o Art. 3º da Resolução Contran Nº 1004, de 21 de dezembro de 2023, relata que o PNATRANS se apoia em seis principais pilares [@conselhonacionaldetrânsito2023]:

-   Gestão da Segurança no Trânsito;

-   Vias Seguras;

-   Segurança Veicular;

-   Educação para o Trânsito;

-   Vigilância, Promoção da Saúde e Atendimento às Vítimas no Trânsito e;

-   Normalização e Fiscalização.

Em relação à Resolução Contran N° 870, de 13 de setembro de 2021 [@conselhonacionaldetrânsito2018], a N° 1004 ratifica o quinto pilar, expandindo a visão de atendimento as vítimas no trânsito. A resolução mais recente ainda adiciona ao PNATRANS os princípios e diretrizes que constituem um sistema seguro de mobilidade, aprofundando os conceitos de iniciativas, ações e produtos promovidos pelos orgãos do Sistema Nacional de Trânsito para cada pilar.

A busca pela fundamentação técnica para a proposição de políticas públicas a respeito da mobilidade segura fomenta o estudo de diversas categorias de modelos preditivos para a sinistralidade no trânsito, tanto para estimar o número de ocorrências quanto para avaliar a influência das variáveis consideradas sobre a ocorrência de sinistros fatais. Em geral, a literatura pertinente apresenta diversos meios distintos para alcançar estes modelos de melhor ajuste: Modelos lineares multivariados foram ajustados para extrair tendências sobre os critérios aferidos [@blumenberg2018; @cai2015], assim como modelos preditivos baseados em cadeia de Markov [@seneta1996; @jin2020]. Outras abordagens utilizam técnicas de análise de séries temporais, utilizando métodos autoregressivos como o ARIMA - Modelo Auto-Regressivo Integrado de Médias Móveis [@al-ghamdi1995] e redes neurais artificiais [@jafari2015].

O código-fonte do trabalho todo está abertamente disponibilizado para acesso como repositório no [perfil do GitHub](https://github.com/ONSV) do Observatório Nacional de Segurança Viária.

## Objetivos

Considerando o presente cenário, este estudo tem como objetivo elaborar um modelo de aprendizado de máquina para a previsão de mortes no trânsito em âmbito nacional no Brasil, investigando dados socioeconômicos e estruturais com o propósito de explorar diversos tipos de tratamentos e análises estatísticas para criar perspectivas futuras a cerca do cenário brasileiro da segurança viária. Posto isso, o projeto também visa avaliar a qualidade de cada tipo de modelo experimentado em expressar o fenômeno real dos óbitos no trânsito, assim como elucidar a influência e relevância de cada variável considerada na construção do modelo preditivo criado com a incidência destes eventos.

## Metodologia

### Coleta de dados

A coleta de dados foi efetuada considerando as principais variáveis teoricamente relacionadas à mortalidade no trânsito, e também considerando os dados disponíveis para o público, amparando a escolha de cada grandeza na literatura previamente revisada. Estes dados são reunidos e pré-processados para a formação de conjuntos de dados específicos para cada método de modelagem, variando com a resolução temporal de cada abordagem (anual, trimestral e mensal).

Dito isto, investigam-se diversas bases a fim de compilar estas informações e extrair dados para uma análise preliminar, anterior a modelagem. Entre as fontes contempladas estão:

-   PIB mensal, fornecido pelo Sistema Gerenciador de Séries Temporais do Banco Central [@bancocentraldobrasil2023], mensurado em dólares;

-   População nacional residente, fornecida pelo sistema DataSUS do Ministério da Saúde [@ministériodasaúde2023b], obtida pelo sistema TABNET;

-   Sinistros em rodovias federais, fornecidos pelo portal de dados abertos da Polícia Rodoviária Federal [@políciarodoviáriafederal2023];

-   Condutores habilitados, fornecidos pelo portal de estatísticas da Secretaria Nacional de Trânsito (Senatran), provenientes do Registro Nacional de Condutores Habiltados (RENACH) [@ministériodostransporte2023];

-   Frota veicular, fornecida pelo portal de estatísticas da Senatran, provenientes Registro Nacional de Veículos Automotores (RENAVAM) [@ministériodostransportes2023];

-   Óbitos em sinistros de trânsito, fornecidos pelo Sistema de Informação de Mortalidade (SIM) do DataSUS [@ministériodasaúde2023a], obtidos com auxílio da biblioteca [`microdatasus`](https://github.com/rfsaldanha/microdatasus) [@microdatasus] da linguagem de programação *R*.

Vale ressaltar que nem todos os dados estão disponíveis em todas as unidades de tempo estudadas, por isso não foram inclusas no processo de criação de certos modelos. As bases de condutores habilitados e população residente, por exemplo, são unicamente anuais, impossibilitando sua utilização no modo trimestral e mensal.

### Modelos

#### Escalas de tempo

Em razão da baixa disponibilidade de dados, os modelos confeccionados em geral contemplam uma janela de tempo de 2011 até a atualidade (2022), sendo as principais unidades de tempo estudadas a anual, a trimestral e a mensal. Ao criar modelos de série temporal, deve-se notar que a abundância de dados a serem modelados tem uma relação direta com a capacidade do modelo em questão de aprender e conseguir expressá-los futuramente, impactando no seu desempenho.

Modelos treinados em âmbito mensal conseguem emitir previsões todo mês, porém perdem precisão quanto mais adiante realizam previsões, enquanto modelos anuais podem predizer com alto desempenho os valores de anos posteriores, mas não são capazes de prever meses ou trimestres. Assim, estas diversas abordagens são testadas a fim de comparar os desempenhos e utilidades de cada método.

#### Análise de Série Temporal x Análise Determinística

É importante ressaltar que há mais de uma maneira de se entender as relações entre os dados e, portanto, mais de uma maneira de interpretá-los em questão do processo de modelagem estatística do problema em mãos. Neste sentido, as metodologias de análise propostas a partir da observação dos dados disponíveis implicam duas possíveis linhas de raciocínio no que se diz a análise estatística: a análise de série temporal e a análise de regressão ou determinística.

A análise de série temporal se apoia no conceito de séries temporais, sendo um conjunto de dados de alguma grandeza ordenada em sequência cronológica, para criar um modelo generalista visando prever as observações futuras baseado nas ocorrências passadas. Este tipo de modelagem assume que o que ocorre no momento atual, neste caso óbitos no trânsito, dependeria, ou possui relação, com o que ocorreu anteriormente. O modelo também leva em consideração o comportamento ao longo do tempo, como sazonalidade, tendência e heteroscedasticidade, e é altamente dependente da *autocorrelação*.

Já a análise de regressão tem como base a criação de um modelo de variáveis *preditadas* (ou dependentes) que dependem de variáveis *preditivas* ou *preditoras* (independentes), criando uma função generalista que expressa a relação destas categorias de variáveis entre si. Diferentemente da análise temporal, a regressão **independe da sequência cronológica dos fatos**, mas é diretamente afetada pela correlação das variáveis independentes com a variável dependente que se deseja prever.

À vista disso, o processo de modelagem pretende essencialmente englobar estas duas principais metodologias de análise de dados, criando modelos de ambas as categorias. Conforme o embasamento teórico acerca da segurança viária, estas modelagens são possíveis pelo fato de que o fenômeno das mortes no trânsito possuem tanto uma correlação expressiva com variáveis externas, quanto dados temporais bem ordenados.

#### Configurações

Modelos estatísticos e de aprendizado de máquina constituem um grandioso conjunto de ferramentas e métodos matemáticos e computacionais para expressar fenômenos naturais por meio de funções e algoritmos. Visando expressar as dinâmicas dos óbitos ocasionados pelo transporte, o primeiro método escolhido por sua simplicidade e versatilidade é a regressão linear, norteada pelo conceito de correlações lineares entre diferentes grandezas numéricas.

Como discutido em @james2021, a regressão linear simples se enquadra como um método estatístico e de aprendizado de máquina que se baseia na relação de uma variável dependente quantitativa $Y$ em função de uma variável independente quantitativa $X$, com $\epsilon$ representando uma variável aleatória sobre o erro associado à estimativa, demonstrando a relação matemática linear entre as grandezas:

$$ Y = \beta_0 + \beta_1X + \epsilon $$

Desta forma, pode-se prever uma imagem de $Y$ ao se injetar um valor em $X$ na equação, dado que estas variáveis tenham uma correlação linear significativa e que os ditos *coeficientes* ou *parâmetros* $\beta_0$ e $\beta_1$ sejam estimados para este modelo. No contexto deste projeto, o objetivo é estimar um modelo capaz de predizer as mortes em relação a mais de uma variável independente, tratando-se então de uma regressão linear múltipla:

$$ Y_i = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_nX_n + \epsilon $$

Neste estudo, esta técnica de regressão é amplamente utilizada em todas as resoluções temporais em razão de sua facilidade de explicação e pelas altas correlações lineares entre as variáveis. Estas correlações estatísticas são expressas em índices numéricos pelas técnicas de correlação linear (de Pearson) e a correlação de Spearman, como diz a @fig-ycorr. Sendo assim, serão apresentados os modelo lineares anual, trimestral e mensal confeccionados com este método.

Adiante, é esperado que alguns tipos de modelos necessitem de uma quantidade maior de dados disponíveis para obterem resultados significantes. Modelos de série temporal possuem apenas uma variável, e necessitam de um conjunto extenso e "limpo" de observações para serem adequadamente ajustados, enquanto modelos regressivos mais complexos, como o Random Forest, são propensos a sobreajuste se não treinados e testados devidamente, algo que é representa uma dificuldade em conjuntos de dados reduzidos.

A base de dados extraída com maior número de observações foi a base em resolução mensal, então os modelos de série temporal SARIMA e Suavização Exponencial assim como o modelo regressor Random Forest foram efetuados apenas no contexto de meses, como indica a @tbl-modelos. Deste modo, após a regressão linear anual, trimestral e mensal, o modelo Random Forest mensal foi concebido utilizando o mesmo intervalo de dados e variáveis:

```{r}
#| echo: false
#| label: tbl-modelos
#| tbl-cap: Tabela de escala temporal para cada modelo

data.frame(
  modelo = c("Regressão Linear", "Random Forest", "SARIMA", "Suavização Exponencial"),
  anual = c(T, F, F, F),
  trimestral = c(T, F, F, F),
  mensal = c(T, T, T, T)
) |> 
  rename_with(str_to_title) |> 
  gt() |> 
  tab_options(
    column_labels.background.color = onsv_palette$blue,
    column_labels.font.weight = "bold"
  ) |>
  tab_style(style = cell_text(color = onsv_palette$blue),
            locations = cells_title()) |> 
  sub_values(values = T, replacement = "\u2713") |> 
  sub_values(values = F, replacement = "\u2717")
```

Conforme @james2021, o Random Forest é um método da família de técnicas conhecidas como árvores de decisão que se baseiam em algoritmos que segregam os dados em estratos ou *ramos*, separando os dados conforme regras de decisão previamente estabelecidas pelo método. Assim, estas árvores "crescem" com base na necessidade do algoritmo em otimizar o processo de divisão dos dados em conjunto menores para melhor expressá-los. O resultado deste algoritmo é uma função estatística que irá retornar um valor previsto com base nas regras de decisões impostas em cada variável preditiva.

```{mermaid}
%%| echo: false
%%| label: fig-diagram
%%| fig-cap: Diagrama demonstrativo do algoritmo de Árvore de Decisões

flowchart TD
    1[Nó Inicial] --> 2(Nó de decisão)
    1 --> 3(Nó de decisão)
    3 --> 4(Nó de decisão)
    4 --> f5[Nó final]
    4 --> f6[Nó final]
    3 --> f3[Nó final]
    2 --> f1[Nó final]
    2 --> f2[Nó final]
```

O *Bagged Trees* é uma evolução da árvore de decisões convencional, onde diversas árvores são construídas simultaneamente com diversos conjuntos de reamostragem aleatória ajustados paralelamente (técnica de *bagging*), sendo a média do resultado de todas as árvores o resultado final da predição. O *Random Forest* é um algoritmo que vai além do *Bagged Trees*: além da criação de múltiplas árvores simultaneamente, ele também reamostra aleatoriamente as variáveis preditivas, selecionando conjuntos diferentes de variáveis para cada árvore. Isto serve para *descorrelacionar* estes atributos, já que altas correlações entre preditivas podem enviesar o modelo final, mostrando que o Random Forest é um algoritmo que pratica seleção de atributos internamente.

Diversas técnicas de aprendizado de máquina requerem valores pré-estabelecidos de hiperparâmetros para o treinamento. Neste caso, este tipo de modelo requer valores iniciais para o número de árvores que se deseja treinar (parâmetro `trees`) e o número de atributos que se deseja reamostrar para cada árvore (parâmetros `mtry`). Estes valores foram arbitrariamente escolhidos como 5000 e 5 respectivamente neste estudo, mas outra possível abordagem seria a otimização de hiperparâmetros, utilizando técnicas como *grid search*.

Em seguida, o estudo é dirigido à análise de série temporal, iniciando pelo modelo SARIMA (**S**easonal **A**uto**r**egressive **I**ntegrated **M**oving **A**verage\*). Como relatado em @shumway2017, este é um método da família ARMA, mais especificamente uma alteração do método ARIMA, conhecido por reduzir ou remover completamente a componente sazonal de uma série temporal univariada. O modelo ARIMA possui três parâmetros que espelham as componentes no seu nome: $p$ para a autoregressão (AR), $d$ para diferenciação (I) e $q$ para média móvel (MA), criando o algoritmo $Arima(p, d, q)$.

A autoregressão é simplesmente uma variação da regressão linear que utiliza de valores anteriores à observação presente como variáveis preditivas invés de outra grandeza, construindo um modelo univariado que gera previsões baseadas em valores prévios. A diferenciação, como citada no parágrafo anterior, visa remover a sazonalidade, enquanto a componente de média móvel têm o objetivo de atualizar a predição conforme a tendência da média. A alteração do modelo SARIMA em relação ao último seria a adição de três novos parâmetros para gerar um ARIMA específico para a componente sazonal da série temporal, assim como um quarto componente $m$ para a periodicidade, tornando a fórmula $Sarima(p,d,q)(P,D,Q)m$.

O último método utilizado foi a Suavização Exponencial de Holt-Winters, ou Suavização Exponencial Tripla. Este método é basicamente uma aplicação de filtragem de sinais, visando aproximar uma função matemática generalista sobre uma série ruidosa para melhor interpretar seu comportamento. Este *alisamento* da série resulta em um modelo simples, mas que pode ser tão eficaz em prever novas observações quanto um modelo ARMA, dependendo da sazonalidade do conjunto de dados.

## Resultados

### Análise Exploratória de Dados

Os conjuntos de dados extraídos e pré-processados em função das unidades de tempo denunciam os comportamentos de cada atributo em relação a passagem dos anos, trimestres e meses. Em destaque, os óbitos servem como um dos principais indicadores da qualidade e disseminação dos sistemas de segurança viária do país, mostrando a evolução das mortes ao longo do tempo:

::: panel-tabset
## Anual

```{r}
#| echo: false
#| fig-cap: Óbitos anuais
#| label: fig-ymortes

rtdeaths |> 
  summarise(.by = ano_ocorrencia, obitos = n()) |> 
  drop_na() |> 
  plot_ly(x = ~ano_ocorrencia, y = ~obitos, 
          type = "scatter", 
          mode = "lines",
          line = list(color = onsv_palette$blue),
          text = ~paste("Vítimas:", obitos, "<br>Ano:", ano_ocorrencia),
          hoverinfo = "text") |> 
  layout(yaxis = list(exponentformat = "none",
                      title = "Óbitos"),
         xaxis = list(title = "Data"),
         separators = ",.")
```

## Trimestral

```{r}
#| echo: false
#| fig-cap: Óbitos trimestrais
#| label: fig-tmortes

rtdeaths |> 
  arrange(data_ocorrencia) |> 
  mutate(trimestre = quarter(data_ocorrencia, type = "date_last"), 
         .before = 1) |> 
  summarise(.by = trimestre, obitos = n()) |> 
  drop_na() |> 
  plot_ly(x = ~trimestre, y = ~obitos,
          type = "scatter",
          mode = "lines",
          line = list(color = onsv_palette$blue),
          text = ~paste("Vítimas:", obitos, "<br>Trimestre:", trimestre),
          hoverinfo = "text") |> 
  layout(yaxis = list(exponentformat = "none",
                      title = "Óbitos"),
         xaxis = list(title = "Data"),
         separators = ",.")
```

## Mensal

```{r}
#| echo: false
#| fig-cap: Óbitos mensais
#| label: fig-mmortes

rtdeaths |> 
  arrange(data_ocorrencia) |> 
  mutate(data = ym(paste0(ano_ocorrencia,"-",month(data_ocorrencia))),
         .before = 1) |> 
  summarise(.by = data, obitos = n()) |> 
  drop_na() |>
  plot_ly(x = ~data, y = ~obitos,
          type = "scatter",
          mode = "lines",
          line = list(color = onsv_palette$blue),
          text = ~paste("Vítimas:", obitos, "<br>Mês:", data),
          hoverinfo = "text") |> 
  layout(yaxis = list(exponentformat = "none",
                      title = "Óbitos"),
         xaxis = list(title = "Data"),
         separators = ",.")
```
:::

Os gráficos de óbitos no trânsito apresentam uma tendência de incremento das vítimas fatais nos últimos três anos. O ano de 2019 atingiu a menor quantidade de óbitos relacionadas ao trânsito nos últimos 10 anos, quando em 2020 a têndencia tornou a crescer. No ano de 2021 houveram 33.813 vítimas fatais, aproximadamente 2000 a mais que em 2019. Em 2022, esse tendência foi levemente atenuada, mantendo um número próximo de óbitos em relação ao ano anterior.

Assim sendo, os demais atributos do conjunto de dados podem ser visualizados em função do tempo, como foi feito para o caso da variável preditada, com o intuito de destacar cada variável preditiva ao longo dos períodos disponíveis:

::: panel-tabset
## Frota veicular (RENAVAM)

::: panel-tabset
## Anual

```{r}
#| echo: false
#| fig-cap: Frota anual
#| label: fig-yfrota

plot_frota_anual <- fleetbr |>
  filter(mes == 7) |> 
  pivot_wider(values_from = frota, names_from = modal) |> 
  mutate(
    automovel = AUTOMOVEL + CAMINHONETE + CAMIONETA + UTILITARIO,
    motocicleta = MOTOCICLETA + CICLOMOTOR + MOTONETA,
    total = TOTAL
  ) |> 
  summarise(
    .by = ano,
    automovel = sum(automovel),
    motocicleta = sum(motocicleta),
    veiculos_total = sum(total)
  ) |> 
  rename(
    "Automóveis" = automovel,
    "Motocicletas" = motocicleta,
    "Veículos totais" = veiculos_total
  ) |> 
  pivot_longer(-ano) |> 
  ggplot(aes(ano, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste("Frota:", value)), size = 0.5) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) + 
    scale_x_continuous(n.breaks = 10) +
    labs(x = "Data", y = "Frota") +
    scale_color_manual(values = paleta)

ggplotly(plot_frota_anual, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")),
         yaxis = list(title = list(standoff = 5)))
```

## Trimestral

```{r}
#| echo: false
#| fig-cap: Frota trimestral
#| label: fig-tfrota

plot_frota_tri <- fleetbr |> 
  pivot_wider(names_from = modal, values_from = frota) |> 
  mutate(
    data = ym(paste0(ano,"-",mes)),
    automovel = AUTOMOVEL + CAMINHONETE + CAMIONETA + UTILITARIO,
    motocicleta = MOTOCICLETA + CICLOMOTOR + MOTONETA
  ) |> 
  rename(total = TOTAL) |> 
  summarise(
    .by = data,
    veiculos = sum(total),
    automovel = sum(automovel),
    motocicleta = sum(motocicleta)
  ) |> 
  mutate(data = quarter(data, type = "date_last"), 
         .before = 1) |> 
  summarise(.by = data,
            across(everything(), last)) |>
  rename(
    "Automóveis" = automovel,
    "Motocicletas" = motocicleta,
    "Veículos totais" = veiculos
  ) |> 
  pivot_longer(-data) |> 
  ggplot(aes(data, value, color = name)) + 
    geom_line() +
    geom_point(aes(text = paste("Frota:", value)), size = 0.5) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years") +
    labs(x = "Data", y = "Frota") +
    scale_color_manual(values = paleta)

ggplotly(plot_frota_tri, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")),
         yaxis = list(title = list(standoff = 5)))
```

## Mensal

```{r}
#| echo: false
#| fig-cap: Frota mensal
#| label: fig-mfrota

plot_frota_mensal <- fleetbr |> 
  pivot_wider(names_from = modal, values_from = frota) |> 
  mutate(
    data = ym(paste0(ano,"-",mes)),
    automovel = AUTOMOVEL + CAMINHONETE + CAMIONETA + UTILITARIO,
    motocicleta = MOTOCICLETA + CICLOMOTOR + MOTONETA
  ) |> 
  rename(total = TOTAL) |> 
  summarise(
    .by = data,
    veiculos = sum(total),
    automovel = sum(automovel),
    motocicleta = sum(motocicleta)
  ) |> 
  rename(
    "Automóveis" = automovel,
    "Motocicletas" = motocicleta,
    "Veículos totais" = veiculos
  ) |> 
  pivot_longer(-data) |> 
  ggplot(aes(data, value, color = name)) +
    geom_line() + 
    geom_point(aes(text = paste("Frota:", value)), size = 0.5) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years") +
    labs(x = "Data", y = "Frota") +
    scale_color_manual(values = paleta)

ggplotly(plot_frota_mensal, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")),
         yaxis = list(title = list(standoff = 5)))
```
:::

## PIB (IBGE, BCB)

::: panel-tabset
## Anual

```{r}
#| echo: false
#| fig-cap: PIB anual
#| label: fig-ypib

plot_pib_anual <- pib_mensal |> 
  summarise(
    .by = ano, 
    pib = sum(pib)
  ) |> 
  filter(ano > 2010) |> 
  ggplot(aes(ano, pib)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("PIB:",pib,"Mi US$")), color = onsv_palette$blue, size = 0.5) +
    scale_x_continuous(n.breaks = 10) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "PIB (Mi US$)")

ggplotly(plot_pib_anual, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```

## Trimestral

```{r}
#| echo: false
#| fig-cap: PIB trimestral
#| label: fig-tpib

plot_pib_tri <- pib_mensal |> 
  mutate(data = quarter(ym(paste0(ano,"-",mes)), type = "date_last")) |> 
  summarise(.by = data, pib = sum(pib)) |> 
  filter(year(data) > 2010) |> 
  ggplot(aes(data, pib)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("PIB:",pib,"Mi US$")), color = onsv_palette$blue, size = 0.5) +
    scale_x_date(date_breaks = "2 years") +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "PIB (Mi US$)")

ggplotly(plot_pib_tri, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```

## Mensal

```{r}
#| echo: false
#| fig-cap: PIB mensal
#| label: fig-mpib

plot_pib_mensal <- pib_mensal |> 
  mutate(data = ym(paste0(ano,"-",mes))) |> 
  summarise(.by = data, pib = sum(pib)) |>
  filter(year(data) > 2010) |> 
  ggplot(aes(data, pib)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("PIB:",pib,"Mi US$")), color = onsv_palette$blue, size = 0.5) +
    scale_x_date(date_breaks = "2 years") +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "PIB (Mi US$)")

ggplotly(plot_pib_mensal, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```
:::

## População

```{r}
#| echo: false
#| fig-cap: População
#| label: fig-popul

plot_populacao <- df_total |> 
  select(populacao, ano) |> 
  drop_na() |> 
  filter(ano > 2010) |> 
  ggplot(aes(ano, populacao)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("População:", populacao)), color = onsv_palette$blue, size = 0.5) +
    scale_x_continuous(breaks = seq(2011, 2021, 1)) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "População")

ggplotly(plot_populacao, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```

## Sinistros em rodovias federais (PRF)

::: panel-tabset
## Anual

```{r}
#| echo: false
#| fig-cap: Sinistros anuais
#| label: fig-yprf

df_prf_plot <- prf_sinistros |> 
  mutate(
    mes = month(data_inversa),
    acidentes_fatais = if_else(
      classificacao_acidente == "Com Vítimas Fatais",
      1, 0, missing = 0
    )
  ) |> 
  summarise(
    .by = c(mes, ano, uf),
    acidentes = n(),
    acidentes_fatais = sum(acidentes_fatais),
    feridos = sum(feridos),
    mortes = sum(mortos)
  ) |> 
  arrange(mes, ano) |> 
  collect()

plot_prf_anual <- df_prf_plot |> 
  summarise(.by = ano, across(.fns = sum, acidentes:mortes)) |> 
  filter(ano > 2010) |> 
  rename(
    "Acidentes" = acidentes,
    "Acidentes fatais" = acidentes_fatais,
    "Feridos" = feridos,
    "Mortos" = mortes
  ) |> 
  pivot_longer(-ano) |> 
  ggplot(aes(ano, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste0(name,": ", value)), size = 0.5) +
    scale_x_continuous(breaks = seq(2011, 2023, 1)) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_color_manual(values = paleta) +
    labs(x = "Data", y = NULL)

ggplotly(plot_prf_anual, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```

## Trimestral

```{r}
#| echo: false
#| fig-cap: Sinistros trimestrais 
#| label: fig-tprf

plot_prf_tri <- df_prf_plot |> 
  mutate(data = quarter(ym(paste0(ano,"-",mes)), type = "date_last")) |> 
  summarise(.by = data, across(.fns = sum, acidentes:mortes)) |> 
  filter(year(data) > 2010) |> 
  rename(
    "Acidentes" = acidentes,
    "Acidentes fatais" = acidentes_fatais,
    "Feridos" = feridos,
    "Mortos" = mortes
  ) |> 
  pivot_longer(-data) |> 
  ggplot(aes(data, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste0(name,": ", value)), size = 0.5) +
    scale_x_date(date_breaks = "2 years") +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_color_manual(values = paleta) +
    labs(x = "Data", y = NULL)

ggplotly(plot_prf_tri, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```

## Mensal

```{r}
#| echo: false
#| fig-cap: Sinistros mensais
#| label: fig-mprf

plot_prf_mensal <- df_prf_plot |> 
  mutate(data = ym(paste0(ano,"-",mes))) |> 
  summarise(.by = data, across(.fns = sum, acidentes:mortes)) |> 
  filter(year(data) > 2010) |> 
  rename(
    "Acidentes" = acidentes,
    "Acidentes fatais" = acidentes_fatais,
    "Feridos" = feridos,
    "Mortos" = mortes
  ) |> 
  pivot_longer(-data) |> 
  ggplot(aes(data, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste0(name,": ", value)), size = 0.5) +
    scale_x_date(date_breaks = "2 years") +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_color_manual(values = paleta) +
    labs(x = "Data", y = NULL)

ggplotly(plot_prf_mensal, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```
:::

## Condutores habilitados (RENACH)

```{r}
#| echo: false
#| fig-cap: Condutores habilitados
#| label: fig-condutores

plot_condutores <- tabela_condutores |> 
  ggplot(aes(ano, condutores)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("Condutores:",condutores)), color = onsv_palette$blue, size = 0.5) +
    scale_x_continuous(breaks = seq(2011, 2023, 1)) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "Condutores")

ggplotly(plot_condutores, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```
:::

Observa-se uma diferença entre os comportamentos de cada atributo ao longo do tempo. Variáveis convencionalmente cumulativas como a frota, a população e o número de condutores habilitados dispõe de um crescimento aproximadamente linear por todo o período de estudo. Todavia, detecta-se que a contagem da população se comportou de forma inesperada em alguns anos. Isso pode representar a diferença entre a população censitária e a população estimada pelo IBGE.

Os dados de rodovias federais flutuam de forma análoga aos óbitos no trânsito, agindo como referência do desempenho da segurança viária em nível nacional de determinado período, com uma sazonalidade pronunciada. Estes dados também mostram claramente como os óbitos são eventos incomuns em comparação com a quantidade de sinistros totais observados. Porém, enquanto a quantidade de sinistros pode variar intensamente ao longo dos anos, o número de óbitos permanece relativamente constante, com uma redução ao longo da janela analisada.

O PIB é o atributo com o comportamento mais particular ao longo do tempo em relação às outras variáveis. Foi utilizado o dólar americano em lugar do real brasileiro a fim de observar a oscilação da moeda em um contexto global e revelar a contribuição histórica da economia nacional. Modelos realizados por @blumenberg2018 e @zhong-xiang2014 utilizam do PIB como um indicador do desempenho socioeconômico do país.

### Correlação

O sucesso da modelagem é inteiramente dependente da intensidade e do tipo de relação estatística que as variáveis possuem entre si. Como anteriormente citado, a regressão linear múltipla bem ajustada infere que as preditivas possuem uma correlação linear forte com a preditora, mas um modelo com baixo desempenho não é necessariamente uma evidência de baixa correlação.

Grandezas que variam juntas em uma correlação linear são ditas colineares, e o fenômeno da colinearidade entre variáveis preditivas pode vir a ocasionar sobreajuste ao modelo. Por isso, é necessário avaliar as correlações não lineares, como apontam os correlogramas, a partir do método de correlação Spearman, nas três escalas temporais:

::: panel-tabset
## Anual

```{r}
#| echo: false
#| fig-cap: Correlação de Spearman Anual
#| label: fig-ycorr

cor_spearman_anual <- df_total |> 
  drop_na() |> 
  select(-c(quilometragem_10_bilhoes, mortos_por_pop, ano)) |> 
  rename(
    `Óbitos` = mortes,
    Automóveis = automovel,
    Motocicletas = motocicleta,
    `Veículos Totais` = veiculos_total,
    PIB = pib,
    `População` = populacao,
    Acidentes = qnt_acidentes,
    `Acidentes fatais` = qnt_acidentes_fatais,
    Feridos = qnt_feridos,
    Condutores = condutores,
    `Mortes PRF` = qnt_mortos
  ) |> 
  cor(method = "spearman")

ggcorrplot(
  cor_spearman_anual,
  lab_col = "white",
  type = "lower",
  lab = T,
  hc.order = T,
  lab_size = 3, 
  tl.srt = 60,
  tl.cex = 12, 
  legend.title = "Correlação",
  colors = c(onsv_palette$blue, "white", onsv_palette$red)
)
```

## Trimestral

```{r}
#| echo: false
#| fig-cap: Correlação de Spearman Trimestral
#| label: fig-tcorr

cor_spearman_trimestral <- dados_mensais |> 
  mutate(data = quarter(data, type = "date_last")) |> 
  summarise(
    .by = data,
    veiculos = last(veiculos),
    automovel = last(automovel),
    motocicleta = last(motocicleta),
    mortes = sum(mortes),
    pib = sum(pib),
    acidentes = sum(acidentes),
    acidentes_fatais = sum(acidentes_fatais),
    feridos = sum(feridos),
    mortes_prf = sum(mortes_prf)
  ) |> 
  select(-data) |> 
  rename(
    `Óbitos` = mortes,
    Automóveis = automovel,
    Motocicletas = motocicleta,
    `Veículos Totais` = veiculos,
    PIB = pib,
    Acidentes = acidentes,
    `Acidentes fatais` = acidentes_fatais,
    Feridos = feridos,
    `Mortes PRF` = mortes_prf
  ) |> 
  cor(method = "spearman")

ggcorrplot(
  cor_spearman_trimestral,
  lab_col = "white",
  type = "lower",
  lab = TRUE, 
  hc.order = T,
  lab_size = 3, 
  tl.srt = 60,
  tl.cex = 12, 
  legend.title = "Correlação",
  colors = c(onsv_palette$blue, "white", onsv_palette$red)
)
```

## Mensal

```{r}
#| echo: false
#| fig-cap: Correlação de Spearman Mensal
#| label: fig-mcorr

cor_spearman_mensal <-dados_mensais |> 
  select(-data) |> 
  rename(
    `Óbitos` = mortes,
    Automóveis = automovel,
    Motocicletas = motocicleta,
    `Veículos Totais` = veiculos,
    PIB = pib,
    Acidentes = acidentes,
    `Acidentes fatais` = acidentes_fatais,
    Feridos = feridos,
    `Mortes PRF` = mortes_prf
  ) |> 
  cor(method = "spearman")

ggcorrplot(
  cor_spearman_mensal,
  lab_col = "white",
  type = "lower",
  lab = TRUE, 
  hc.order = T,
  lab_size = 3, 
  tl.srt = 60,
  tl.cex = 12, 
  legend.title = "Correlação",
  colors = c(onsv_palette$blue, "white", onsv_palette$red)
)
```
:::

Em todos os correlagramas se encontram valores significativos para praticamente todas as variáveis, sendo que as matrizes de 𝑝-valores calculados rejeitam a hipótese nula com facilidade para todos os atributos, todos os casos.

### Taxas de óbitos

O diagnóstico da segurança no trânsito de uma uma região em um determinado intervalo de tempo é um dos principais tópicos no campo da mobilidade segura, visto que as variáveis que influenciam a saúde no trânsito não são um consenso acadêmico absoluto. Este fato fomenta a pesquisa e desenvolvimento de novas metodologias e indicadores específicos para a análise estatística do cenário brasileiro que melhor interpretem os dados disponíveis e representem o fenômeno real da sinistralidade de maneira verossímil. @ferraz2023 disserta sobre a questão da quantificação e qualificação da sinistralidade por meio da determinação de índices utilizando das mortes, população e frota como parâmetros para estabelecer valores representativos do nível de segurança do local.

Estes índices são usualmente referidos em função de altas casas decimais para salientar a significância dos valores de cada taxa calculada. As taxas que direcionaram o presente estudo na avaliação da sinistralidade anual foram as vítimas fatais por 100 mil habitantes e vítimas fatais por 10 mil veículos, como indicado:

```{r}
#| echo: false
#| fig-cap: Taxas de óbitos
#| label: fig-taxa-obitos

plot_taxas <- df_total |> 
  select(ano, veiculos_total, populacao, mortes) |> 
  drop_na() |> 
  mutate(taxa_hab = (mortes/populacao) * 100000,
         taxa_veic = (mortes/veiculos_total) * 10000) |> 
  select(ano, taxa_hab, taxa_veic) |> 
  rename(
    "Óbitos por 100.000 hab" = taxa_hab,
    "Óbitos por 10.000 veículos" = taxa_veic
  ) |> 
  pivot_longer(-ano) |> 
  ggplot(aes(ano, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste0(name,": ", round(value, 2)))) +
    facet_wrap(vars(name), scales = "free_y") +
    labs(y = "Índices", x = "Data") +
    scale_color_manual(values = paleta)

ggplotly(plot_taxas, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```

As duas taxas anunciam tendências distintas a cerca da fatalidade no trânsito brasileiro. Enquanto o índice de mortes por veículos oferece uma perspectiva de estabilização no número de vítimas, a taxa de habitantes corrobora à visão de que as mortes estão inclinadas ao aumento na década atual. Deve-se levar em consideração que esta diferença de comportamente pode resultar da evolução da frota veicular e da população nacional em taxas distintas.

### Resultados dos modelos

A avaliação de desempenho de cada modelo foi gerada a partir da necessidade e especificações de cada caso. Visualizações podem ser criadas para todos os modelos a fim de apresentar a proximidade das previsões em relação aos valores reais. Métricas de erros são utilizadas para quantificar a taxa de acertos de cada modelo, notando-se que em modelos com maior disponibilidade de dados (trimestral e mensal) foi efetuada a repartição de amostras para treino e para teste.

A repartição dividiu as amostras com uma proporção de 75% dos dados para o treinamento dos modelos, sendo o restante utilizado na validação das previsões pelo cálculo do Erro Quadrado Médio Absoluto (*Root Mean Squared Error* - RMSE), Erro Médio Absoluto *(Mean Squared Error* - MAE) e o 𝑅^2^, ou coeficiente de determinação. A técnica de repartição de treino e teste é consideravelmente mais simples que o método de validação cruzada comumente utilizado em modelos de aprendizado de máquina mais robustos, mas pode ser mais adequada à *databases* menores, dado que a validação cruzada não influenciou na performance dos modelos e foi abandonada devido ao gasto computacional desnecessário. Já no caso do modelo anual, que possui um conjunto ainda menor de dados, a repartição é inviável e a validação foi dada com o mesmo conjunto do treinamento.

#### Regressão Linear Múltipla

A análise de regressão linear múltipla foi a abordagem mais extensamente utilizada durante a produção do estudo, podendo ser dividida entre as escalas temporais anual, trimestral e mensal. Cada métrica e modelo são extraídos apresentados para avaliação das suas performances, com os resultados segregados por unidade de tempo.

##### Anual

```{r}
#| include: false

metricas <- metric_set(rmse, mae, rsq)

dados_modelo_2023 <- list(
  drop_na(count(rename(rtdeaths, ano = ano_ocorrencia), ano, name = "mortes")),
  summarise(filter(fleetbr, modal == "TOTAL", mes == 7), 
            .by = ano, frota = sum(frota)),
  prf_sinistros |> 
    filter(classificacao_acidente == "Com Vítimas Fatais") |> 
    count(ano, name = "acids_fatais") |> 
    collect(),
  prf_sinistros |> 
    count(ano, name = "acids") |> 
    collect(),
  tabela_condutores
) |> 
  reduce(full_join, by = "ano") |> 
  arrange(ano)

rec_anual_2023 <-
  recipe(x = drop_na(dados_modelo_2023), mortes ~ .) |> 
  remove_role(ano, old_role = "predictor") |> 
  step_normalize(all_numeric_predictors())

modelo_anual_2023 <-
  linear_reg() |> 
  set_engine("lm")
  
wflow_anual_2023 <-
  workflow() |> 
  add_model(modelo_anual_2023) |> 
  add_recipe(rec_anual_2023) |> 
  fit(drop_na(dados_modelo_2023))

pred_anual_2023 <- bind_cols(
  dados_modelo_2023,
  predict(wflow_anual_2023, dados_modelo_2023),
  predict(wflow_anual_2023, dados_modelo_2023, type = "conf_int")
)

metricas_anual <- metricas(data = pred_anual_2023, truth = mortes, estimate = .pred)
```

Para o caso da análise anual, as previsões emitidas são comparadas com as ocorrências reais, enquanto as métricas são baseadas no mesmo conjunto de ajuste do modelo:

::: panel-tabset
## Série

```{r}
#| echo: false
#| fig-cap: Previsão anual para RL
#| label: fig-ypred-rl

plot_pred_anual <- pred_anual_2023 |> 
  select(ano, mortes, .pred, .pred_lower, .pred_upper) |> 
  pivot_longer(
    cols = c(.pred, mortes),
    names_to = "Tipo",
    values_to = "Mortes"
  ) |> 
  mutate(
    Tipo = if_else(Tipo == "mortes", "Óbitos reais", "Óbitos previstos")
  ) |> 
  filter(ano>2010) |> 
  ggplot(aes(ano, Mortes, color = Tipo)) +
    geom_ribbon(
      aes(ymax = .pred_upper, ymin = .pred_lower),
      fill = "grey",
      color = "grey",
      alpha = 0.25
    ) +
    geom_line() +
    geom_point(aes(text = paste0(Tipo,": ", round(Mortes, 0))), size = 0.5) +
    scale_x_continuous(breaks = seq(2011,2023,1)) +
    scale_y_continuous(labels = comma_format(big.mark = ".")) +
    scale_color_manual(values = paleta) + 
    labs(x = NULL, y = NULL)

ggplotly(plot_pred_anual, tooltip = "text")
```

## Previsto x Real

```{r}
#| echo: false
#| fig-cap: Previsto x Real anual RL
#| label: fig-yqqplot-rl

plot_qq_anual <- pred_anual_2023 |> 
  select(.pred, mortes, ano) |> 
  drop_na() |> 
  rename(Previsto = .pred, Real = mortes) |> 
  ggplot(aes(x = Real, y = Previsto)) +
  geom_point(aes(text = paste0("Óbitos reais: ", Real, "<br>Óbitos previstos: ", round(Previsto, 0), "<br>Data: ", ano)), color = onsv_palette$blue) +
  geom_abline(
    linewidth = 1, 
    alpha = 0.5, 
    color = onsv_palette$blue, 
    lty = "dashed"
  ) +
  scale_y_continuous(labels = comma_format(big.mark = ".")) + 
  scale_x_continuous(labels = comma_format(big.mark = ".")) +
  coord_obs_pred()

ggplotly(plot_qq_anual, tooltip = "text")
```

## Métricas

```{r}
#| echo: false
#| tbl-cap: Métricas para RL anual
#| label: tbl-ymetric-rl

metricas_anual |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",", digits = 2)) |> 
  kable(
    align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

Como é demonstrado pelo amplo intervalo de confiança preditado (área em cinza no gráfico), o fato do conjunto de dados anuais ser relativamente pequeno confere uma incerteza atribuída à essa abordagem. Para 2023, o modelo prevê 34.631 óbitos no trânsito brasileiro, uma diferença de 737 vítimas e um aumento de aproximadamente 2,1% em relação ao valor real do ano anterior (2022).

As métricas RMSE e MAE são melhor aplicadas de forma comparativa entre diferentes ajustes, sendo utilizados para auxiliar na seleção de atributos para o treinamento do modelo. Foi concluído que as melhores variáveis para explicar as ocorrências de óbitos no trânsito para esta categoria de modelo foram a frota total, os acidentes totais e fatais em rodovias federais e os condutores habilitados.

Como este modelo em específico possui maior variedade de atributos, a combinação de diversas configurações de preditivas foi feita manualmente para melhor filtrar as variáveis úteis. Componentes como a população, o PIB e as mortes em rodovias federais foram considerados muito colineares, prejudicando a performance do modelo. Na @tbl-coefs, estão explicitados os melhores atributos e seus coeficientes:

```{r}
#| echo: false
#| tbl-cap: Coeficientes para modelo anual
#| label: tbl-coefs

wflow_anual_2023 |>
  tidy() |>
  mutate(
    "Variável" = c(
      "Intercepto Y",
      "Frota",
      "Acidentes fatais",
      "Acidentes",
      "Condutores"
    ),
    .before = 1
  ) |> 
  select(1, 3, 6) |> 
  rename(
    Coeficientes = estimate,
    `P-valor` = p.value
  ) |> 
  mutate(across(where(is.numeric), round, 2)) |> 
  gt() |> 
  tab_options(
    column_labels.background.color = onsv_palette$blue,
    column_labels.font.weight = "bold"
  ) |>
  tab_style(style = cell_text(color = onsv_palette$blue),
            locations = cells_title())
```

##### Trimestral

Os dados utilizados foram obtidos por meio do agrupamento trimestral dos dados mensais, sendo constituída uma base de dados específica para o ajuste deste modelo de regressão. As métricas e visualizações para avaliação da performance foram as mesmas do modelo anual, porém, a partir deste, todos os próximos modelos são reamostrados em conjuntos de treino e teste para a validação adequada:

```{r}
#| include: false

df_frota_2023 <- fleetbr |> 
  pivot_wider(names_from = modal, values_from = frota) |> 
  mutate(
    data = ym(paste0(ano,"-",mes)),
    automovel = AUTOMOVEL + CAMINHONETE + CAMIONETA + UTILITARIO,
    motocicleta = MOTOCICLETA + CICLOMOTOR + MOTONETA
  ) |> 
  rename(total = TOTAL) |> 
  summarise(
    .by = data,
    veiculos = sum(total),
    automovel = sum(automovel),
    motocicleta = sum(motocicleta)
  )

df_mortes_2023 <- rtdeaths |> 
  mutate(mes = month(data_ocorrencia),
         ano = year(data_ocorrencia),
         data = ym(paste0(ano, "-", mes))) |> 
  count(data, name = "mortes") |> 
  drop_na()

df_pib_2023 <- pib_mensal |> 
  mutate(data = ym(paste0(ano, "-", mes))) |> 
  group_by(data) |> 
  summarise(pib)

df_prf_2023 <- prf_sinistros |> 
  collect() |> 
  mutate(
    acidentes_fatais = if_else(
      classificacao_acidente == "Com Vítimas Fatais", 1, 0, missing = 0
    ),
    mes = month(data_inversa),
    data = ym(paste0(ano, "-", mes))
  ) |> 
  summarise(
    .by = data,
    acidentes = n(),
    acidentes_fatais = sum(acidentes_fatais),
    feridos = sum(feridos),
    mortes_prf = sum(mortos)
  ) |> 
  arrange(data)
  
dados_mensais_2023 <- 
  list(df_frota_2023, df_mortes_2023, df_pib_2023, df_prf_2023) |> 
  reduce(full_join, by = "data") |> 
  arrange(data)

df_trimestre_2023 <- dados_mensais_2023 |>
  mutate(
    trimestre = quarter(data),
    data = quarter(data, type = "date_last")
  ) |> 
  group_by(data, trimestre) |> 
  summarise(
    veiculos = last(veiculos),
    automovel = last(automovel),
    motocicleta = last(motocicleta),
    mortes = sum(mortes),
    pib = sum(pib),
    acidentes = sum(acidentes),
    acidentes_fatais = sum(acidentes_fatais),
    feridos = sum(feridos),
    mortes_prf = sum(mortes_prf)
  ) |> 
  ungroup()

splits_trimestre <- initial_split(drop_na(df_trimestre_2023), prop = 3/4)
train_trimestre <- training(splits_trimestre)
test_trimestre <- testing(splits_trimestre)

rec <- 
  recipe(df_trimestre_2023, mortes ~ .) |> 
  remove_role(c(mortes_prf, trimestre, data), old_role = "predictor") |> 
  step_normalize(all_numeric_predictors())

model <-
  linear_reg() |>
  set_engine("lm")

lm_wflow <-
  workflow() |> 
  add_model(model) |> 
  add_recipe(rec)

lm_wflow_fit <-
  lm_wflow |> 
  fit(train_trimestre)

pred_trimestre_2023 <- bind_cols(
  df_trimestre_2023,
  predict(lm_wflow_fit, df_trimestre_2023),
  predict(lm_wflow_fit, df_trimestre_2023, type = "conf_int")
)

metricas_trimestre <- bind_cols(
  test_trimestre,
  predict(lm_wflow_fit, test_trimestre)
) |> 
  metricas(truth = mortes, estimate = .pred)
```

::: panel-tabset
## Série

```{r}
#| echo: false
#| fig-cap: Previsão trimestral para RL
#| label: fig-tpred-rl

plot_pred_tri <- pred_trimestre_2023 |> 
  select(data, trimestre, mortes, .pred_lower, .pred_upper, .pred) |> 
  filter(year(data) > 2010) |>  
  pivot_longer(cols = c(.pred, mortes),
               names_to = "Tipo",
               values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes, color = Tipo)) +
    geom_ribbon(
      aes(ymax = .pred_upper, ymin = .pred_lower),
      fill = "grey",
      color = "grey",
      alpha = 0.25
    ) +
    scale_y_continuous(labels = comma_format(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years") +
    geom_line() +
    geom_point(aes(text = paste0(Tipo,": ", round(Mortes, 0))), size = 0.5) +
    scale_color_manual(values = paleta) + 
    labs(x = NULL, y = NULL)

ggplotly(plot_pred_tri, tooltip = "text")
```

## Previsto x Real

```{r}
#| echo: false
#| fig-cap: Previsto x Real trimestral RL
#| label: fig-tqqplot-rl

plot_qq_tri <- pred_trimestre_2023 |> 
  select(data, .pred, mortes) |> 
  drop_na() |> 
  rename(Previsto = .pred, Real = mortes) |> 
  ggplot(aes(x = Real, y = Previsto)) +
  geom_point(aes(text = paste0("Óbitos reais: ", Real, "<br>Óbitos previstos: ", round(Previsto, 0), "<br>Data: ", data)), color = onsv_palette$blue) +
  geom_abline(
    linewidth = 1, 
    alpha = 0.5, 
    color = onsv_palette$blue, 
    lty = "dashed"
  ) +
  scale_y_continuous(labels = comma_format(big.mark = ".")) + 
  scale_x_continuous(labels = comma_format(big.mark = ".")) +
  coord_obs_pred()

ggplotly(plot_qq_tri, tooltip = "text")
```

## Métricas

```{r}
#| echo: false
#| tbl-cap: Métricas para RL trimestral
#| label: tbl-tmetric-rl

metricas_trimestre |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",", digits = 2)) |> 
  kable(
    align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

O grafico da @fig-tpred-rl espelha visualmente a periodicidade e sazonalidade trimestral da mortalidade no trânsito, revelando a existência de épocas de maior risco no trânsito em todos os anos, independente da tendência da série temporal de óbitos. Como esperado, a maior disponibilidade de dados resulta em alterações positivas nas métricas de erros em relação à escala temporal anual.

##### Mensal

A escala mensal é a menor unidade temporal abordada para o estudo e permite observar a sazonalidade dos sinistros:

```{r}
#| include: false

split_2023 <- initial_split(drop_na(dados_mensais_2023), prop = 0.8)

train_2023 <- training(split_2023)
test_2023 <- testing(split_2023)

rec_mensal_2023 <-
  recipe(train_2023, mortes ~ .) |> 
  remove_role(c(mortes_prf, data), old_role = "predictor") |> 
  step_normalize(all_numeric_predictors())

lm_mensal_2023 <-
  linear_reg() |> 
  set_engine("lm")

lm_wflow_mensal_2023 <-
  workflow() |> 
  add_model(lm_mensal_2023) |> 
  add_recipe(rec_mensal_2023) |> 
  fit(train_2023)

pred_mensal_2023 <-
  bind_cols(
    dados_mensais_2023,
    predict(lm_wflow_mensal_2023, dados_mensais_2023),
    predict(lm_wflow_mensal_2023, dados_mensais_2023, type = "conf_int")
  )

metricas_mensal <- metricas(pred_mensal_2023, truth = mortes, estimate = .pred)
```

::: panel-tabset
## Série

```{r}
#| echo: false
#| fig-cap: Previsão mensal para RL
#| label: fig-mpred-rl

plot_pred_mensal <- pred_mensal_2023 |> 
  filter(year(data) > 2010) |> 
  pivot_longer(cols = c(.pred, mortes),
               names_to = "Tipo",
               values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes, color = Tipo)) +
    geom_ribbon(aes(ymax = .pred_upper, ymin = .pred_lower),
                fill = "grey", color = "grey", alpha = 0.25) +
    geom_line() +
    geom_point(aes(text = paste0(Tipo,": ", round(Mortes, 0))), size = 0.5) +
    scale_y_continuous(labels = comma_format(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years") +
    labs(x = NULL, y = NULL) +
    scale_color_manual(values = paleta)

ggplotly(plot_pred_mensal, tooltip = "text")
```

## Previsto x Real

```{r}
#| echo: false
#| fig-cap: Previsto x Real mensal RL
#| label: fig-mqqplot-rl

plot_qq_mensal <- pred_mensal_2023 |> 
  select(data, .pred, mortes) |> 
  drop_na() |> 
  rename(Previsto = .pred, Real = mortes) |> 
  ggplot(aes(x = Real, y = Previsto)) +
  geom_point(aes(text = paste0("Óbitos reais: ", Real, "<br>Óbitos previstos: ", round(Previsto, 0), "<br>Data: ", data)), color = onsv_palette$blue) +
  geom_abline(
    linewidth = 1, 
    alpha = 0.5, 
    color = onsv_palette$blue, 
    lty = "dashed"
  ) +
  scale_y_continuous(labels = comma_format(big.mark = ".")) + 
  scale_x_continuous(labels = comma_format(big.mark = ".")) +
  coord_obs_pred()

ggplotly(plot_qq_mensal, tooltip = "text")
```

## Métricas

```{r}
#| echo: false
#| tbl-cap: Métricas para RL mensal
#| label: tbl-mmetric-rl

metricas_mensal |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",", digits = 2)) |> 
  kable(
    align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

Uma das características notáveis deste modelo é sua capacidade de descrever observações anômalas ao decorrer dos anos, onde os óbitos ultrapassam os intervalos de confiança estipulados pelo modelo, mesmo que este apresente uma alta performance e capacidade preditiva segundo as métricas.

#### Regressor Random Forest

O segundo modelo utilizado para a análise de regressão, como anteriormente explicado, foi o Regressor Random Forest, ajustado apenas para o contexto mensal. Esta técnica dispensa a seleção de atributos manual que fora necessária para o caso da regressão linear, já que possui um algoritmo seletor interno. Sendo assim, este modelo é treinado e validado no mesmo conjunto mensal anteriormente processado:

```{r}
#| include: false

rf <- 
  rand_forest(
    mode = "regression",
    mtry = 5,
    trees = 5000
  ) |> 
  set_engine("ranger")

rf_wflow <- 
  workflow() |> 
  add_model(rf) |> 
  add_recipe(rec_mensal_2023) |>
  fit(train_2023)

rf_pred <- bind_cols(
  predict(rf_wflow, drop_na(dados_mensais_2023, veiculos)),
  drop_na(dados_mensais_2023, veiculos)
)

metricas_rf <- bind_cols(
  predict(rf_wflow, test_2023),
  test_2023
) |> 
  metricas(truth = mortes, estimate = .pred)
```

::: panel-tabset
## Série

```{r}
#| echo: false
#| fig-cap: Previsão por RF
#| label: fig-pred-rf

plot_pred_rf <- rf_pred |> 
  pivot_longer(c(.pred, mortes), names_to = "Tipo", values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes, color = Tipo)) +
    geom_line() +
    geom_point(aes(text = paste0(Tipo,": ", round(Mortes, 0))), size=0.5) +
    scale_color_manual(values = paleta) +
    scale_y_continuous(labels = comma_format(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years") +
    labs(x = NULL, y = NULL)

ggplotly(plot_pred_rf, tooltip = "text")
```

## Previsto x Real

```{r}
#| echo: false
#| fig-cap: Previsto x Real para RF
#| label: fig-qqplot-rf

plot_qq_rf <- rf_pred |> 
  select(data, .pred, mortes) |> 
  drop_na() |> 
  rename(Previsto = .pred, Real = mortes) |> 
  ggplot(aes(x = Real, y = Previsto)) +
  geom_point(aes(text = paste0("Óbitos reais: ", Real, "<br>Óbitos previstos: ", round(Previsto, 0), "<br>Data: ", data)), color = onsv_palette$blue) +
  geom_abline(
    linewidth = 1, 
    alpha = 0.5, 
    color = onsv_palette$blue, 
    lty = "dashed"
  ) +
  scale_y_continuous(labels = comma_format(big.mark = ".")) + 
  scale_x_continuous(labels = comma_format(big.mark = ".")) +
  coord_obs_pred()

ggplotly(plot_qq_rf, tooltip = "text")
```

## Métricas

```{r}
#| echo: false
#| tbl-cap: Métricas para RF
#| label: tbl-metric-rf

metricas_rf |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",", digits = 2)) |> 
  kable(
    align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

O Random Forest se sobressai visualmente no gráfico de valores previstos sobre valores reais, visto que as previsões aparentam se aproximar mais à linha de convergência em relação ao modelo anterior. Apesar da incapacidade do algoritmo em gerar intervalos de confiança, o Random Forest raramente estima valores anômalos, apontando que é menos sensível a *outliers*. Como mencionado na descrição teórica deste algoritmo, este efeito é associado a reamostragem que o modelo faz enquanto está construindo as "árvores" pela técnica *bagging*, reduzindo o enviesamento dos valores discrepantes.

#### SARIMA

```{r}
#| include: false

df_mortes <- rtdeaths |> 
  arrange(data_ocorrencia) |> 
  mutate(data = ym(paste0(ano_ocorrencia, '-', month(data_ocorrencia))),
         .before = 1) |> 
  summarise(.by = data, mortes = n()) |> 
  drop_na()

ts <- ts(df_mortes$mortes, start = c(1996, 1), end = c(2022, 12), frequency = 12)

decomposed <- decompose(ts)
```

Após as análises regressivas, a próxima abordagem estátistica estudada é a análise de séries temporais univariadas, sobretudo iniciada pela condução de experimentos utilizando do método SARIMA. Entretanto, antes da modelagem propriamente dita, algumas evidências podem ser reunidas para indicar a viabilidade destes métodos temporais, como a decomposição da série temporal:

::: panel-tabset
## Série Original

```{r}
#| echo: false
#| fig-cap: Série temporal de óbitos
#| label: fig-ts

autoplot(
  ts, 
  color = onsv_palette$blue, 
  ylab = "Mortes", xlab = "Data")
```

## Tendência

```{r}
#| echo: false
#| fig-cap: Componente de tendência
#| label: fig-trend

autoplot(
  decomposed$trend,
  color = onsv_palette$blue,
  ylab = "Mortes", xlab = "Data")
```

## Sazonalidade

```{r}
#| echo: false
#| fig-cap: Componente de sazonalidade
#| label: fig-season

autoplot(
  decomposed$seasonal,
  color = onsv_palette$blue,
  ylab = "Mortes", xlab = "Data")
```

## Residual

```{r}
#| echo: false
#| fig-cap: Componente residual
#| label: fig-residual

autoplot(
  decomposed$random,
  color = onsv_palette$blue,
  ylab = "Mortes", xlab = "Data")
```
:::

A série decomposta é observada para determinar se o comportamento da quantidade de mortes ao longo do tempo é característico de uma série modelável pelo SARIMA. A tendência é um forte indicativo de que há uma média móvel neste fenômeno, mas a grande quantidade de resíduo aponta que não há uma sazonalidade tão bem estabelicida e cíclica. Assim, outros métodos usados para o entendimento da sinistrilidade no tempo são os gráficos ACF (Fator de Autocorrelação) e PACF (Fator de Autocorrelação Parcial):

```{r}
#| echo: false
#| fig-cap: Gráficos de autocorrelação
#| label: fig-autocor

par(mfrow = c(1, 2))
acf(ts, main = "ACF")
pacf(ts, main = "PACF")
par(mfrow = c(1, 1))
```

Desta maneira, atenta-se que os dados possuem altas correlações com diversos períodos de atraso de forma indireta e direta. Em especial, a quantidade de óbitos em um certo mês aparenta estar profundamente relacionada ao número de óbitos no mesmo mês no ano anterior, visto que há uma alta correlação no *lag* de 12 meses para ambos os gráficos.

Estas análises são úteis para a decisão manual de valores iniciais para os parâmetros do SARIMA. Todavia, outra forma mais adequada e automatizada de chegar ao ajuste ideal para o modelo é a função de ajuste automático `auto.arima()` do pacote [`forecast`](https://github.com/robjhyndman/forecast) [@hyndman2008], uma implementação do método que busca a melhor combinação de parâmetros baseado nos critérios de seleção de modelo AIC (*Akaike Information Criterion*) e BIC (*Bayesian Information Criterion*).

```{r}
#| include: false

sarima <- auto.arima(
  ts,
  stationary = F,
  seasonal = T
)

sarima_pred <- cbind(fit = sarima$fitted, 
                  forecast = forecast(sarima, h = 12)$mean, 
                  mortes = sarima$x,
                  .pred_lower = forecast(sarima, h = 12)$lower,
                  .pred_upper = forecast(sarima, h = 12)$upper)
sarima_pred <- 
  data.frame(sarima_pred, data = zoo::as.Date(time(sarima_pred))) |> 
  mutate(.pred = coalesce(forecast, fit), .before = 1) |> 
  select(-c(fit, forecast))

metricas_sarima <- metricas(sarima_pred, truth = mortes, estimate = .pred)
```

::: panel-tabset
## Previsão

```{r}
#| echo: false
#| fig-cap: fig-pred-arima 
#| label: Previsão por SARIMA

plot_pred_sarima <- sarima_pred |> 
  filter(year(data) > 2010) |> 
  pivot_longer(c(.pred, mortes), names_to = "Tipo", values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", 
                        "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes)) +
    geom_ribbon(aes(ymin = .pred_lower.80., ymax = .pred_upper.80.), fill = "grey80", alpha = 0.5) +
    geom_ribbon(aes(ymin = .pred_lower.95., ymax = .pred_upper.95.), fill = "grey90", alpha = 0.5) +
    geom_line(aes(color = Tipo)) + 
    geom_point(aes(text = paste0(Tipo,": ", round(Mortes, 0)), color = Tipo), size = 0.5) +
    scale_color_manual(values = paleta) +
    labs(x = NULL, y = NULL) +
    scale_y_continuous(labels = comma_format(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years")

ggplotly(plot_pred_sarima, tooltip = "text")
```

## Métricas

```{r}
#| echo: false
#| tbl-cap: Métricas para SARIMA
#| label: tbl-metrics-arima

metricas_sarima |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",", digits = 2)) |> 
  kable(
    align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

Por ser um modelo autoregressivo univariado, as previsões emitidas pelo SARIMA são ruidosas, produzindo amplos intervalos de confiança. Modelos dessa categoria possuem baixa longevidade visto que seu desempenho diminui conforme a distância da previsão ao conjunto original. Em comparação a modelos determinísticos, não necessitam de outras variáveis para ter resultados e são, em geral, mais simples computacionalmente.

#### Suavização Exponencial

```{r}
#| include: false

ets <- HoltWinters(ts)

ets_pred <- cbind(fit = ets$fitted[, "xhat"], 
                  forecast = forecast(ets, h = 12)$mean, 
                  mortes = ets$x,
                  .pred_lower = forecast(ets, h = 12)$lower,
                  .pred_upper = forecast(ets, h = 12)$upper)
ets_pred <- 
  data.frame(ets_pred, data = zoo::as.Date(time(ets_pred))) |> 
  mutate(.pred = coalesce(forecast, fit), .before = 1) |> 
  select(-c(fit, forecast))

metricas_ets <- metricas(ets_pred, truth = mortes, estimate = .pred)
```

A Suavização Exponencial Holt-Winters é o segundo modelo de análise de séries temporais estudado, o qual possui uma abordagem teórica distinta do anterior. Sendo um modelo de suavização, este pretende aproximar uma função que filtre a série temporal original e expresse o comportamento dos dados de forma simplificada.

::: panel-tabset
## Previsão

```{r}
#| echo: false
#| fig-cap: Previsão por ETS
#| label: fig-pred-ets

plot_pre_ets <- ets_pred |> 
  filter(year(data) > 2010) |> 
  pivot_longer(c(.pred, mortes), names_to = "Tipo", values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", 
                        "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes)) +
    geom_ribbon(aes(ymin = .pred_lower.80., ymax = .pred_upper.80.), fill = "grey80", alpha = 0.5) +
    geom_ribbon(aes(ymin = .pred_lower.95., ymax = .pred_upper.95.), fill = "grey90", alpha = 0.5) +
    geom_line(aes(color = Tipo)) +
    geom_point(aes(text = paste0(Tipo,": ", round(Mortes, 0)), color = Tipo), size = 0.5) +
    scale_color_manual(values = paleta) +
    labs(x = NULL, y = NULL) +
    scale_y_continuous(labels = comma_format(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years")

ggplotly(plot_pre_ets, tooltip = "text")
```

## Métricas

```{r}
#| echo: false
#| tbl-cap: Métricas para ETS
#| label: tbl-metrics-ets

metricas_ets |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",", digits = 2)) |> 
  kable(
    align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

Modelos de suavização são ainda mais simplistas que modelos ARIMA já que constituem métodos de filtragem espectral convencionais. Usualmente, a literatura destaca que modelos autoregressivos são mais adequados para séries temporais ruidosas, enquanto modelos exponenciais respondem melhor à séries sazonais. Outra possível vantagem da exponenciação é sua priorização de dados mais novos, dado que este método reduz o peso de cada observação exponencialmente conforme a distância do valor mais recente [@shumway2017].

### Comparação de Modelos

Após os experimentos, a seleção de um modelo final é feita de forma comparativa, considerando não apenas os índices de métricas de erros calculados mas também as características e capacidades de cada modelo individualmente. A @tbl-compare demonstra os valores de desempenho dos modelos:

```{r}
#| echo: false
#| tbl-cap: Comparação de métricas para todos os modelos
#| label: tbl-compare

rbind(
  mutate(metricas_anual, modelo = "Regressão Linear", resol = "Anual"),
  mutate(metricas_trimestre, modelo = "Regressão Linear", resol = "Trimestral"),
  mutate(metricas_mensal, modelo = "Regressão Linear", resol = "Mensal"),
  mutate(metricas_rf, modelo = "Random Forest Regressor", resol = "Mensal"),
  mutate(metricas_ets, modelo = "Exponential Smoothing", resol = "Mensal"),
  mutate(metricas_sarima, modelo = "SARIMA", resol = "Mensal")
) |>
  select(-.estimator) |>
  pivot_wider(names_from = .metric, values_from = .estimate) |>
  rename_with(toupper, rmse:rsq) |>
  group_by(resol) |>
  gt(rowname_col = "model") |>
  cols_label(modelo = "Modelo") |>
  fmt_number(decimals = 2,
             sep_mark = ".",
             dec_mark = ",") |>
  tab_options(
    column_labels.background.color = onsv_palette$blue,
    column_labels.font.weight = "bold"
  ) |>
  tab_style(style = cell_text(color = onsv_palette$blue),
            locations = cells_title())
```

RMSE e MAE melhoram em resoluções menores de unidades de tempo, sendo consequência indireta da maior disponibilidade de dados para o treinamento do modelo. Mesmo assim, será perceptível que, por exemplo, um modelo mensal bem ajustado não prevê um ano inteiro melhor que um modelo anual, por efeito da acumulação de erros associados às previsões de cada mês. Como implica a @tbl-compare, o modelo linear anual aparenta ter resultados mais plausíveis que o mensal, mesmo tendo um desempenho de RMSE e MAE inferior. Em relação ao RSQ, o modelo anual apresenta o melhor desempenho.

```{r}
#| include: false

pred_list <- list(
  rename(
    pred_anual_2023, 
    pred.anual = .pred, 
    upper.anual = .pred_upper, 
    lower.anual = .pred_lower
  ),
  summarise(
    mutate(pred_trimestre_2023, ano = year(data)),
    .by = ano,
    pred.trimestral = sum(.pred),
    upper.trimestral = sum(.pred_upper),
    lower.trimestral = sum(.pred_lower)
  ),
  summarise(
    mutate(pred_mensal_2023, ano = year(data)),
    .by = ano,
    pred.mensal = sum(.pred),
    upper.mensal = sum(.pred_upper),
    lower.mensal = sum(.pred_lower)
  ),
  summarise(
    mutate(rf_pred, ano = year(data)),
    .by = ano,
    pred.rf = sum(.pred)
  ),
  summarise(
    mutate(sarima_pred, ano = year(data)),
    .by = ano,
    pred.sarima = sum(.pred),
    upper.sarima = sum(.pred_upper.80.),
    lower.sarima = sum(.pred_lower.80.)
  ),
  summarise(
    mutate(ets_pred, ano = year(data)),
    .by = ano,
    pred.ets = sum(.pred),
    upper.ets = sum(.pred_upper.80.),
    lower.ets = sum(.pred_lower.80.)
  )
)
```

```{r}
#| echo: false
#| tbl-cap: Previsões de todos os modelos para 2023
#| label: tbl-preds

pred_list |> 
  reduce(left_join, by = "ano") |> 
  select(c(ano, starts_with(c("pred","upper","lower")))) |> 
  last() |> 
  pivot_longer(-ano) |> 
  mutate(
    modelo = str_remove(str_extract(name, "\\..*"), "\\."),
    tipo = str_remove(str_extract(name, "^(.*?)\\."), "\\.")
  ) |> 
  select(-c(ano, name)) |> 
  pivot_wider(values_from = value, names_from = tipo) |> 
  mutate(
    modelo = case_match(
      modelo,
      "anual" ~ "Linear Anual",
      "trimestral" ~ "Linear Trimestral",
      "mensal" ~ "Linear Mensal",
      "rf" ~ "RF Mensal",
      "sarima" ~ "SARIMA Mensal",
      "ets" ~ "ETS Mensal"
    )
  ) |> 
  gt() |> 
  cols_label(
    modelo = "Modelo",
    pred = "Previsão",
    upper = "Máx.",
    lower = "Mín."
  ) |> 
  fmt_number(decimals = 0,
             sep_mark = ".",
             dec_mark = ",") |>
  tab_options(
    column_labels.background.color = onsv_palette$blue,
    column_labels.font.weight = "bold"
  ) |>
  tab_style(style = cell_text(color = onsv_palette$blue),
            locations = cells_title()) |> 
  sub_missing(missing_text = "-") |> 
  tab_footnote(
    footnote = "Algoritmo não produz intervalo de confiança",
    locations = cells_body(columns = modelo,
                           rows = modelo == "RF Mensal"),
    placement = "left"
  ) |> 
  opt_footnote_marks("standard")
```

Nota-se que ambos os métodos de análise de séries temporais prevêem uma queda, enquanto os modelos regressivos estipulam que as fatalidades crescem. Na @fig-facet-pred, os resultados de cada modelo foram agrupados e somados por ano para visualização de cada série temporal individualmente:

```{r}
#| echo: false
#| fig-cap: Gráficos de previsões para 2023 
#| label: fig-facet-pred

dodge <- position_dodge(1)

plot_comparison <- pred_list |> 
  reduce(left_join, by = "ano") |> 
  select(c(ano, mortes, starts_with("pred"))) |> 
  pivot_longer(starts_with("pred"), names_to = "tipo", values_to = "pred") |>
  mutate(tipo = case_match(tipo,
                           "pred.anual" ~ "Linear Anual",
                           "pred.trimestral" ~ "Linear Trimestral",
                           "pred.mensal" ~ "Linear Mensal",
                           "pred.rf" ~ "RF Mensal",
                           "pred.sarima" ~ "SARIMA Mensal",
                           "pred.ets" ~ "ETS Mensal")) |> 
  ggplot(aes(ano, mortes)) +
    geom_line(aes(y = pred, color = "Óbitos previstos")) +
    geom_point(aes(y = pred, color = "Óbitos previstos", 
                   text = paste("Previstos:", round(pred)))) +
    geom_line(aes(color = "Óbitos reais")) +
    geom_point(aes(color = "Óbitos reais", 
                   text = paste("Óbitos:", mortes))) +
    scale_color_manual(values = c(onsv_palette$blue, onsv_palette$yellow)) +
    scale_x_continuous(breaks = seq(2011, 2023, 1), limits = c(2011, NA)) +
    scale_y_continuous(labels = label_comma(decimal.mark = ",", big.mark = ".")) +
    theme(axis.text.x = element_text(angle = 90)) +
    facet_wrap(tipo ~ .) +
    labs(x = NULL, y = NULL)
    
ggplotly(plot_comparison, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```

```{r}
#| include: false

load(here("data/populacao.rda"))
```

Em questão das taxas anteriormente discutidas para quantificação dos óbitos em relação à população e à frota veicular, novos valores podem ser calculados sobre as previsões a fim de averiguar a mudança destas taxas em função do tempo e tipo de modelo:

::: panel-tabset
## Óbitos por 100 mil hab.

```{r}
#| echo: false
#| fig-cap: Previsões por 100 mil habitantes
#| label: fig-pred-hab

plot_taxa_popul <- pred_list |> 
  append(list(populacao)) |> 
  reduce(left_join, by = "ano") |> 
  select(c(ano, mortes, populacao, starts_with("pred"))) |> 
  pivot_longer(starts_with("pred"), names_to = "tipo", values_to = "pred") |> 
  mutate(taxa_pred = round((pred/populacao) * 100000, 2),
         taxa_real = round((mortes/populacao) * 100000, 2),
         tipo = case_match(tipo,
                           "pred.anual" ~ "Linear Anual",
                           "pred.trimestral" ~ "Linear Trimestral",
                           "pred.mensal" ~ "Linear Mensal",
                           "pred.rf" ~ "RF Mensal",
                           "pred.sarima" ~ "SARIMA Mensal",
                           "pred.ets" ~ "ETS Mensal")) |> 
  ggplot(aes(ano, taxa_real)) +
    geom_line(aes(y = taxa_pred, color = "Óbitos previstos")) +
    geom_point(aes(y = taxa_pred, color = "Óbitos previstos", 
                   text = paste("Taxa prevista:", taxa_pred))) +
    geom_line(aes(color = "Óbitos reais")) +
    geom_point(aes(color = "Óbitos reais", 
                   text = paste("Taxa real:", taxa_real))) +
    scale_color_manual(values = c(onsv_palette$blue, onsv_palette$yellow)) +
    scale_x_continuous(breaks = seq(2011, 2021, 1), limits = c(2011, 2021)) +
    theme(axis.text.x = element_text(angle = 90)) +
    facet_wrap(tipo ~ .) +
    labs(x = NULL, y = NULL)
  
ggplotly(plot_taxa_popul, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```

## Óbitos por 10 mil veic.

```{r}
#| echo: false
#| fig-cap: Previsões por 10 mil veículos
#| label: fig-pred-veic

plot_taxa_frota <- pred_list |> 
  reduce(left_join, by = "ano") |> 
  select(c(ano, mortes, frota, starts_with("pred"))) |> 
  pivot_longer(starts_with("pred"), names_to = "tipo", values_to = "pred") |> 
  mutate(taxa_pred = round((pred/frota) * 10000, 2),
         taxa_real = round((mortes/frota) * 10000, 2),
         tipo = case_match(tipo,
                           "pred.anual" ~ "Linear Anual",
                           "pred.trimestral" ~ "Linear Trimestral",
                           "pred.mensal" ~ "Linear Mensal",
                           "pred.rf" ~ "RF Mensal",
                           "pred.sarima" ~ "SARIMA Mensal",
                           "pred.ets" ~ "ETS Mensal")) |> 
  ggplot(aes(ano, taxa_real)) +
    geom_line(aes(y = taxa_pred, color = "Óbitos previstos")) +
    geom_point(aes(y = taxa_pred, color = "Óbitos previstos", 
                   text = paste("Taxa prevista:", taxa_pred))) +
    geom_line(aes(color = "Óbitos reais")) +
    geom_point(aes(color = "Óbitos reais", 
                   text = paste("Taxa real:", taxa_real))) +
    scale_color_manual(values = c(onsv_palette$blue, onsv_palette$yellow)) +
    scale_x_continuous(breaks = seq(2011, 2021, 1), limits = c(2011, 2021)) +
    theme(axis.text.x = element_text(angle = 90)) +
    facet_wrap(tipo ~ .) +
    labs(x = NULL, y = NULL)

ggplotly(plot_taxa_frota, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```
:::

## Conclusão

Os modelos regressivos desenvolvidos antecipam uma tendência ao aumento relativo nas vítimas de sinistros de trânsito em 2023, uma revelação preocupante à presente situação da segurança viária no Brasil. Em contrapartida, os modelos de séries tempoais prevêem uma possível diminuição, provavelmente devido a sensibilidade destes tipos de técnicas à sazonalidade. Por isso, a análise de regressão permanece como a abordagem mais interessante no contexto do fenômeno estudado, tanto pela qualidade da previsão quanto pela capacidade explicativa deste tipo de metodologia.

É fundamental também destacar que as soluções de segurança viária não dependem apenas de atributos da mobilidade urbana. Inúmeros fatores socioeconômicos e de infraestrutura podem afetar o desempenho da segurança. O cenário atual da segurança viária brasileira apresenta alguns desafios e deficiências que podem impactar na conquista das metas de redução estabelecidas em âmbito nacional pelo PNATRANS. Os dados previstos mostram um desempenho abaixo do ideal no combate da fatalidade no trânsito brasileiro, conferindo uma perspectiva pessimista para a década atual no Brasil e, caso este cenário não seja amenizado com antecedência, é improvável a ocorrência de avanços significativos nos objetivos da Segunda Década de Ação pela Segurança no Trânsito.

## Referências
