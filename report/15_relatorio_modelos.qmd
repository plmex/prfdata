---
title: "Modelo Preditivo de Mortes no Trânsito Brasileiro"
date: 2023-12-19

smooth-scroll: true

authors:
  - name: João Pedro Melani Saraiva
  - name: Pedro Augusto Borges dos Santos

description: "Modelo de aprendizado de máquina orientado a dados de segurança viária para o reconhecimento de padrões e previsão de mortes no trânsito"

title-block-banner: true

format: 
  html:
    editor: visual
    dpi: 300
    number-sections: true

knitr: 
  opts_chunk: 
    fig.align: center

bibliography: references.bib
toc: true
toc-title: Sumário

lang: pt
---

```{r include=FALSE}
# packages
library(tidyverse)
library(gt)
library(forecast)
library(ggcorrplot)
library(onsvplot)
library(knitr)
library(here)
library(tidymodels)
library(kableExtra)
library(fleetbr)
library(roadtrafficdeaths)
library(plotly)
library(arrow)

# opções de display
theme_set(theme_onsv())
set.seed(123)

# load dos dados
load(here("data","tabela_total.rda"))
load(here("data","tabela_total_mensal.rda"))
load(here("data/pib_mensal.rda"))
load(here("data","tabela_condutores.rda"))
temp <- tempfile()
download.file("https://github.com/ONSV/prfdata/releases/download/v0.2.0/prf_sinistros.zip", temp)
unzip(temp, exdir = tempdir())
unlink(temp)
prf_sinistros <- open_dataset(paste(sep = "\\", file.path(tempdir()), "prf_sinistros"))

# paleta
paleta = as_vector(unname(onsv_palette))

# supressão dos warnings
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Introdução

### Referenciais Teóricos

O presente cenário mundial acerca de mortes e lesões relacionadas à sinistros de trânsito posam sérios desafios à saúde pública global, e as tendências evidenciadas pelos dados atuais indicam que esta realidade deve perdurar pelo futuro próximo [@worldhealthorganization2018]. Sendo uma das causas de mortes mais comuns no mundo, as ocorrências de sinistros de trânsito afetam principalmente pedestres, ciclistas e motociclistas, além de induzir severos danos materiais, tanto em questão de propriedade particular quanto pública. Isto estimula países a buscarem métodos estimativos sobre os efeitos sociais, econômicos e epidemiológicos da taxa de mortes no trânsito e como se traduzem em custos e perdas na produtividade da sociedade em geral [@rodríguez2020].

A segurança viária pode ser um valioso indicador do estado de desenvolvimento de uma região, visto que é uma característica do avanço da mobilidade urbana. Entende-se que as mortes no trânsito dependem de diversos fatores estruturais, socioeconômicos e ambientais do contexto urbano [@zhong-xiang2014], o que implica que elevadas taxas de sinistros viários colaboram no diagnóstico de problemas da segurança pública em geral, despertando o debate político sobre a regulamentação das normas viárias e apontando a carência dos sistemas da união em combater estes eventos.

Apesar da crescente adesão por itens de segurança veicular, os sinistros de trânsito permanecem como um problema de saúde pública, já que fazem parte de um agravo que repercute por toda a sociedade [@andrade2019], sendo a oitava maior causa de óbitos em todas as faixas etárias e a principal entre indivíduos de 5 a 29 anos [@worldhealthorganization2018]. Como previsto por modelos estatísticos prévios à 2020 [@blumenberg2018], o Brasil apresentou baixo desempenho em cumprir a meta estabelecida pela Primeira Década de Ações pela Segurança no Trânsito. Neste cenário, o Plano Nacional de Redução de Mortes e Lesões no Trânsito (PNATRANS) foi desenvolvido para guiar as ações pela mobilidade segura nacional durante o período da Segunda Década de Ação pela Segurança no Trânsito [@ministériodostransporte2018], na intenção de aprimorar o desempenho da segurança viária em relação a década passada, se alinhando aos Objetivos de Desenvolvimento Sustentável estabelecidos pela Agenda 2030 da Organização das Nações Unidas (ONU). Para atingir tais metas, o Art. 3º da Resolução Contran Nº 870 relata que o PNATRANS se apoia em seis principais pilares: gestão da segurança no trânsito, vias seguras, segurança veicular, educação para o trânsito, atendimento às vítimas, e normalização e fiscalização [@conselhonacionaldetrânsito2018].

A busca pela fundamentação técnica para a proposição de políticas públicas a respeito da mobilidade segura fomenta o estudo de diversas categorias de modelos preditivos para a mortalidade no trânsito, tanto para estimar o número de ocorrências quanto para avaliar a influência das variáveis consideradas sobre a ocorrência de sinistros fatais. Em geral, a literatura pertinente apresenta diversos meios distintos para alcançar estes modelos de melhor ajuste: Modelos lineares multivariados foram ajustados para extrair tendências sobre os critérios aferidos [@blumenberg2018; @cai2015], assim como modelos preditivos baseados em cadeia de Markov [@seneta1996; @jin2020]. Outras abordagens utilizam técnicas de análise de séries temporais, utilizando métodos autoregressivos como o ARIMA - Modelo Auto-Regressivo Integrado de Médias Móveis [@al-ghamdi1995] e redes neurais artificiais [@jafari2015].

### Objetivos

Considerando o presente cenário, este estudo tem como objetivo elaborar um modelo de aprendizado de máquina para a previsão de mortes no trânsito em âmbito nacional no Brasil, investigando dados socioeconômicos e estruturais com o propósito de explorar diversos tipos de tratamentos e análises estatísticas para criar perspectivas futuras a cerca do cenário brasileiro da segurança viária. Posto isso, o projeto também visa avaliar a qualidade de cada tipo de modelo experimentado em expressar o fenômeno real dos óbitos no trânsito, assim como elucidar a influência e relevância de cada variável considerada na construção do dispositivo preditivo criado com a incidência destes eventos.

## Metodologia

### Coleta de dados

A coleta de dados foi efetuada considerando as principais variáveis teoricamente relacionadas à mortalidade em trânsito disponíveis para o público, amparando a escolha de cada grandeza na literatura previamente revisada. Estes dados são reunidos e pré-processados para a formação de conjuntos de dados específicos para cada método de modelagem, variando com a resolução temporal de cada abordagem (anual, trimestral e mensal).

Dito isto, investigam-se diversas bases e fornecedores distintos a fim de compilar estas informações e extrair dados para uma análise preliminar, anterior a modelagem. Entre as fontes contempladas estão:

-   PIB mensal, fornecido pelo Sistema Gerenciador de Séries Temporais do Banco Central [@bancocentraldobrasil2023], coletado em dólares;

-   População nacional residente, fornecida pelo sistema DataSUS do Ministério da Saúde [@ministériodasaúde2023b], obtida pelo TABNET;

-   Sinistros em rodovias federais, fornecidos pelo portal de dados abertos da Polícia Rodoviária Federal [@políciarodoviáriafederal2023];

-   Condutores habilitados, fornecidos pelo portal de estatísticas da Secretaria Nacional de Trânsito (Senatran) do Registro Nacional de Condutores Habiltados (RENACH) [@ministériodostransporte2023];

-   Frota veicular, fornecida pelo portal de estatísticas da Senatran do Registro Nacional de Veículos Automotores (RENAVAM) [@ministériodostransportes2023];

-   Óbitos em trânsito, fornecidos pelo Sistema de Informação de Mortalidade (SIM) do DataSUS [@ministériodasaúde2023a], obtidos pela biblioteca [`microdatasus`](https://github.com/rfsaldanha/microdatasus) [@microdatasus] da linguagem de programação estatística *R*.

Vale ressaltar que nem todos os atributos estão disponíves em todas as unidades de tempo estudadas, por isso não foram inclusas no processo de criação de certos modelos. As bases de condutores habilitados e população residente, por exemplo, são unicamente anuais, impossibilitando sua utilização no modo trimestral e mensal.

### Modelos

#### Escalas de tempo

Em razão da escassa disponibilidade de dados temporais, os modelos confeccionados em geral contemplam uma janela de tempo de 2011 até a atualidade, sendo as principais unidades de tempo estudadas a anual, a trimestral e a mensal. Ao criar modelos de série temporal, deve-se notar que a abundância de dados a serem modelados tem uma relação direta com a capacidade do modelo em questão de aprender e conseguir expressá-los futuramente, impactando no seu desempenho.

Modelos treinados em âmbito mensal conseguem emitir previsões todo mês, porém perdem precisão quanto mais adiante prevém, enquanto modelos anuais podem predizer com alto desempenho os valores de anos posteriores, mas não são capazes de prever meses ou trimestres. Assim, estas diversas abordagens são aferidas a fim de comparar os desempenhos e utilidades de cada método entre si.

#### Análise de Série Temporal x Análise Determinística

É importante ressaltar que há mais de uma maneira de se entender as relações entre os dados e, portanto, mais de uma maneira de interpretá-los em questão do processo de modelagem estatística do problema em mãos. Neste sentido, as metodologias de análise propostas a partir da observação dos dados disponíveis implicam duas possíveis linhas de racioncínio no que se diz a análise estatística: a análise de série temporal e a análise de regressão ou determinística.

A análise de série temporal se apoia no conceito de séries temporais, sendo um conjunto de dados de alguma grandeza ordenada em sequência cronológica, para criar um modelo generalista visando prever as observações futuras baseado nas ocorrências passadas. Este tipo de modelagem assume que o que ocorre no momento atual, neste caso óbitos no trânsito, dependeria, ou possui relação, com o que ocorreu anteriormente. Este tipo de modelo também leva em consideração o comportamento ao longo do tempo, como sazonalidade, tendência e heteroscedasticidade, e é altamente dependente da *autocorrelação*.

Já a análise de regressão tem como base a criação de um modelo de variáveis *preditadas* que dependem de variáveis *preditivas* ou *preditoras*, criando uma função generalista que expressa a relação destas categorias de variáveis entre si. Diferentemente da análise temporal, a regessão independe da sequência cronológica dos fatos, mas é diretamente afetada pela correlação das variáveis independentes com a variável dependente que se deseja prever.

À vista disso, o processo de modelagem pretende essencialmente englobar estas duas principais metodologias de análise de dados, criando modelos de ambas as categorias. Conforme o embasamente teórico acerca da segurança viária, estas modelagens são possíveis pelo fato de que o fenômeno das mortes em trânsito possuem tanto uma correlação expressiva com variáveis externas, quanto dados temporais bem ordenados.

#### Configurações

Modelos estatísticos e de aprendizado de máquina constituem um grandioso conjunto de ferramentas e métodos matemáticos e computacionais para expressar fenômenos naturais por meio de funções e algoritmos. Visando expressar as dinâmicas dos óbitos ocasionados pelo transporte, o primeiro método escolhido por sua simplicidade e versatilidade é a regressão linear, norteada pelo conceito de correlações lineares entre diferentes grandezas numéricas.

A regressão linear simples se enquadra como um método estatístico e de aprendizado de máquina que se baseia na relação de uma variável dependente quantitativa $Y$ em função de uma variável independente quantitativa $X$, com $\epsilon$ representando uma variável aleatória sobre o erro associado à estimativa, demonstrando a relação matemática linear entre as grandezas:

$$ Y = \beta_0 + \beta_1X + \epsilon $$

Desta forma, pode-se prever uma imagem de $Y$ ao se injetar um valor em $X$ na equação, dado que estas variáveis tenham uma correlação linear significativa e que os ditos *coeficientes* ou *parâmetros* $\beta_0$ e $\beta_1$ sejam estimados para este modelo. No contexto deste projeto, o objetivo é estimar um modelo capaz de predizer as mortes em relação a mais de uma variável independente, tratando-se então de uma regressão linear múltipla:

$$ Y_i = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_nX_n + \epsilon $$

Neste estudo, esta técnica de regressão é amplamente utilizada em todas as resoluções temporais em razão de sua facilidade de explicação e pelas altas correlações lineares entre as variáveis. Estas correlações estatísticas são expressas em índices numéricos pelas técnicas de correlação linear (de Pearson) e a correlação de Spearman, como diz a figura X. Sendo assim, serão apresentados os modelo lineares anual, trimestral e mensal confeccionados com este método.

::: callout-important
## Figura

linkar a figura das correlações na figura X
:::

Adiante, é esperado que alguns tipos de modelos necessitem de uma quantidade maior de dados disponíveis para obterem resultados significantes. Modelos de série temporal possuem apenas uma variável, e necessitam de um conjunto extenso e "limpo" de observações para serem adequadamente ajustados, enquanto modelos regressivos mais complexos, como o Random Forest, são propensos a sobreajuste se não treinados e testados devidamente, algo que é impossível em conjuntos de dados curtos.

A base de dados extraída com maior número de observações foi a base em resolução mensal, então os modelos de série temporal SARIMA e Suavização Exponencial assim como o modelo regressor Random Forest foram efetuados apenas no contexto de meses, como indica a tabela X. Deste modo, após a regressão linear anual, trimestral e mensal, o modelo Random Forest mensal foi concebido utilizando o mesmo intervalo de dados e variáveis:

::: callout-important
## Tabela

Tabela mostrando todos os modelos, o tipo de análise e para que resoluções foram utilizadas
:::

O Random Forest é um método da família de técnicas conhecidas como árvores de decisão que se baseiam em algoritmos que segregram os dados em estratos ou *ramos*, separando os dados conforme regras de decisão previamente estabelecidas pelo método. Assim, estas árvores "crescem" com base na necessidade do algoritmo em otimizar o processo de divisão dos dados em conjunto menores para melhor expressá-los. O resultado deste algoritmo é uma função estatística que irá retornar um valor preditado com base nas regras de decisões impostas em cada variável preditiva.

::: callout-important
## Figura

exemplo de árvore de decisão
:::

O *Bagged Trees* é uma evolução da árvore de decisões convencional, onde diversas árvores são construídas simultaneamente com diversos conjuntos de reamostragem aleatória ajustados paralelamente (técnica de *bagging*), sendo a média do resultado de todas as árvores o resultado final da predição. O *Random Forest* é um algoritmo que vai além do *Bagged Trees*: além da criação de múltiplas árvores simultaneamente, ele também reamostra aleatoriamente as variáveis preditivas, selecionando conjuntos diferentes de variáveis para cada árvore. Isto serve para *descorrelacionar* estes atributos, já que altas correlações entre preditivas podem enviesar o modelo final, mostrando que o Random Forest é um algoritmo que pratica seleção de atributos internamente.

Diversas técnicas de aprendizado de máquina requerem valores pré-estabelecidos de hiperparâmetros para o treinamento. Neste caso, este tipo de modelo requer valores iniciais para o número de árvores que se deseja treinar (parâmetro `trees`) e o número de atributos que se deseja reamostrar para cada árvore (parâmetros `mtry`). Estes valores foram arbitrariamente escolhidos como 5000 e 5 respectivamente neste estudo, mas outra possível abordagem seria a otimização de hiperparâmetros, utilizando técnicas como *grid search*.

Em seguida, o estudo é dirigido à análise de série temporal, iniciando pelo modelo SARIMA (***S**easonal **A**uto**r**egressive **I**ntegrated **M**oving **A**verage*). Este é um método da família ARMA, mais especificamente uma alteração do método ARIMA, conhecido por reduzir ou remover completamente a componente sazonal de uma série temporal univariada. O modelo ARIMA possui três parâmetros que espelham as componentes no seu nome: $p$ para a autoregressão (AR), $d$ para diferenciação (I) e $q$ para média móvel (MA), criando o algoritmo $Arima(p, d, q)$.

A autoregressão é simplesmente uma variação da regressão linear que utiliza de valores anteriores à observação presente como variáveis preditivas invés de outra grandeza, construindo um modelo univariado que gera previsões baseadas em valores prévios. A diferenciação, como citada no parágrafo anterior, visa remover a sazonalidade, enquanto a componente de média móvel têm o objetivo de atualizar a predição conforme a tendência da média. A alteração do modelo SARIMA em relação ao último seria a adição de três novos parâmetros para gerar um ARIMA específico para a componente sazonal da série temporal, assim como um quarto componente $m$ para a periodicidade, tornando a fórmula $Sarima(p,d,q)(P,D,Q)m$.

O último método utilizado foi a Suavização Exponencial de Holt-Winters, ou Suavização Exponencial Tripla. Este método é basicamente uma aplicação de filtragem de sinais, visando aproximar uma função matemática generalista sobre uma série ruidosa para melhor interpretar seu comportamento. Este *alisamento* da série resulta em um modelo simples, mas que pode ser tão eficaz em prever novas observações quanto um modelo ARMA, dependendo da sazonalidade do conjunto de dados.

## Resultados

### Análise Exploratória de Dados

Os conjuntos de dados extraídos e pré-processados em função das unidades de tempo denunciam os comportamentos de cada atributo em relação a passagem dos anos, trimestres e meses. Em destaque, os óbitos servem como um dos principais indicadores da qualidade e disseminação dos sistemas de segurança viária da união, mostrando a evolução das mortes ao longo do tempo:

::: panel-tabset
## Anual

```{r}
#| echo: false

rtdeaths |> 
  summarise(.by = ano_ocorrencia, obitos = n()) |> 
  drop_na() |> 
  plot_ly(x = ~ano_ocorrencia, y = ~obitos, 
          type = "scatter", 
          mode = "lines",
          line = list(color = onsv_palette$blue),
          text = ~paste("Vítimas:", obitos, "<br>Ano:", ano_ocorrencia),
          hoverinfo = "text") |> 
  layout(yaxis = list(exponentformat = "none",
                      title = "Óbitos"),
         xaxis = list(title = "Data"),
         separators = ",.")
```

## Trimestral

```{r}
#| echo: false

rtdeaths |> 
  arrange(data_ocorrencia) |> 
  mutate(trimestre = quarter(data_ocorrencia, type = "date_last"), 
         .before = 1) |> 
  summarise(.by = trimestre, obitos = n()) |> 
  drop_na() |> 
  plot_ly(x = ~trimestre, y = ~obitos,
          type = "scatter",
          mode = "lines",
          line = list(color = onsv_palette$blue),
          text = ~paste("Vítimas:", obitos, "<br>Trimestre:", trimestre),
          hoverinfo = "text") |> 
  layout(yaxis = list(exponentformat = "none",
                      title = "Óbitos"),
         xaxis = list(title = "Data"),
         separators = ",.")
```

## Mensal

```{r}
#| echo: false

rtdeaths |> 
  arrange(data_ocorrencia) |> 
  mutate(data = ym(paste0(ano_ocorrencia,"-",month(data_ocorrencia))),
         .before = 1) |> 
  summarise(.by = data, obitos = n()) |> 
  drop_na() |>
  plot_ly(x = ~data, y = ~obitos,
          type = "scatter",
          mode = "lines",
          line = list(color = onsv_palette$blue),
          text = ~paste("Vítimas:", obitos, "<br>Mês:", data),
          hoverinfo = "text") |> 
  layout(yaxis = list(exponentformat = "none",
                      title = "Óbitos"),
         xaxis = list(title = "Data"),
         separators = ",.")
```
:::

Os gráficos históricos para óbitos em trânsito denunciam uma tendência ao incremento das mortes anuais nos últimos três anos. O cenário de 2019 atingiu a menor quantidade de mortes relacionadas ao trânsito nos últimos 10 anos, quando em 2020 a têndencia voltou a crescer. No ano de 2021 houveram 33.813 vítimas, aproximadamente 2000 a mais que em 2019. Em 2022, esse tendência foi levemente atenuada, mantendo um número próximo de óbitos em relação ao ano anterior.

Assim sendo, os demais atributos do conjunto de dados podem ser visualizados em função do tempo, como foi feito para o caso da variável preditada, com o intuito de destacar a evolução de cada variável preditiva ao longo dos períodos disponíveis:

::: panel-tabset
## Frota veicular (RENAVAM)

::: panel-tabset
## Anual

```{r}
#| echo: false

plot_frota_anual <- fleetbr |>
  filter(mes == 7) |> 
  pivot_wider(values_from = frota, names_from = modal) |> 
  mutate(
    automovel = AUTOMOVEL + CAMINHONETE + CAMIONETA + UTILITARIO,
    motocicleta = MOTOCICLETA + CICLOMOTOR + MOTONETA,
    total = TOTAL
  ) |> 
  summarise(
    .by = ano,
    automovel = sum(automovel),
    motocicleta = sum(motocicleta),
    veiculos_total = sum(total)
  ) |> 
  rename(
    "Automóveis" = automovel,
    "Motocicletas" = motocicleta,
    "Veículos totais" = veiculos_total
  ) |> 
  pivot_longer(-ano) |> 
  ggplot(aes(ano, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste("Frota:", value)), size = 0.5) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) + 
    scale_x_continuous(n.breaks = 10) +
    labs(x = "Data", y = "Frota") +
    scale_color_manual(values = paleta)

ggplotly(plot_frota_anual, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")),
         yaxis = list(title = list(standoff = 5)))
```

## Trimestral

```{r}
#| echo: false

plot_frota_tri <- fleetbr |> 
  pivot_wider(names_from = modal, values_from = frota) |> 
  mutate(
    data = ym(paste0(ano,"-",mes)),
    automovel = AUTOMOVEL + CAMINHONETE + CAMIONETA + UTILITARIO,
    motocicleta = MOTOCICLETA + CICLOMOTOR + MOTONETA
  ) |> 
  rename(total = TOTAL) |> 
  summarise(
    .by = data,
    veiculos = sum(total),
    automovel = sum(automovel),
    motocicleta = sum(motocicleta)
  ) |> 
  mutate(data = quarter(data, type = "date_last"), 
         .before = 1) |> 
  summarise(.by = data,
            across(everything(), last)) |>
  rename(
    "Automóveis" = automovel,
    "Motocicletas" = motocicleta,
    "Veículos totais" = veiculos
  ) |> 
  pivot_longer(-data) |> 
  ggplot(aes(data, value, color = name)) + 
    geom_line() +
    geom_point(aes(text = paste("Frota:", value)), size = 0.5) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years") +
    labs(x = "Data", y = "Frota") +
    scale_color_manual(values = paleta)

ggplotly(plot_frota_tri, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")),
         yaxis = list(title = list(standoff = 5)))
```

## Mensal

```{r}
#| echo: false

plot_frota_mensal <- fleetbr |> 
  pivot_wider(names_from = modal, values_from = frota) |> 
  mutate(
    data = ym(paste0(ano,"-",mes)),
    automovel = AUTOMOVEL + CAMINHONETE + CAMIONETA + UTILITARIO,
    motocicleta = MOTOCICLETA + CICLOMOTOR + MOTONETA
  ) |> 
  rename(total = TOTAL) |> 
  summarise(
    .by = data,
    veiculos = sum(total),
    automovel = sum(automovel),
    motocicleta = sum(motocicleta)
  ) |> 
  rename(
    "Automóveis" = automovel,
    "Motocicletas" = motocicleta,
    "Veículos totais" = veiculos
  ) |> 
  pivot_longer(-data) |> 
  ggplot(aes(data, value, color = name)) +
    geom_line() + 
    geom_point(aes(text = paste("Frota:", value)), size = 0.5) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_x_date(date_breaks = "2 years") +
    labs(x = "Data", y = "Frota") +
    scale_color_manual(values = paleta)

ggplotly(plot_frota_mensal, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")),
         yaxis = list(title = list(standoff = 5)))
```
:::

## PIB (IBGE, BCB)

::: panel-tabset
## Anual

```{r}
#| echo: false

plot_pib_anual <- pib_mensal |> 
  summarise(
    .by = ano, 
    pib = sum(pib)
  ) |> 
  filter(ano > 2010) |> 
  ggplot(aes(ano, pib)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("PIB:",pib,"Mi US$")), color = onsv_palette$blue, size = 0.5) +
    scale_x_continuous(n.breaks = 10) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "PIB (Mi US$)")

ggplotly(plot_pib_anual, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```

## Trimestral

```{r}
#| echo: false

plot_pib_tri <- pib_mensal |> 
  mutate(data = quarter(ym(paste0(ano,"-",mes)), type = "date_last")) |> 
  summarise(.by = data, pib = sum(pib)) |> 
  filter(year(data) > 2010) |> 
  ggplot(aes(data, pib)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("PIB:",pib,"Mi US$")), color = onsv_palette$blue, size = 0.5) +
    scale_x_date(date_breaks = "2 years") +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "PIB (Mi US$)")

ggplotly(plot_pib_tri, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```

## Mensal

```{r}
#| echo: false

plot_pib_mensal <- pib_mensal |> 
  mutate(data = ym(paste0(ano,"-",mes))) |> 
  summarise(.by = data, pib = sum(pib)) |>
  filter(year(data) > 2010) |> 
  ggplot(aes(data, pib)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("PIB:",pib,"Mi US$")), color = onsv_palette$blue, size = 0.5) +
    scale_x_date(date_breaks = "2 years") +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "PIB (Mi US$)")

ggplotly(plot_pib_mensal, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```
:::

## População

```{r}
#| echo: false

plot_populacao <- df_total |> 
  select(populacao, ano) |> 
  drop_na() |> 
  filter(ano > 2010) |> 
  ggplot(aes(ano, populacao)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("População:", populacao)), color = onsv_palette$blue, size = 0.5) +
    scale_x_continuous(breaks = seq(2011, 2021, 1)) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "População")

ggplotly(plot_populacao, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```

## Sinistros em rodovias federais (PRF)

::: panel-tabset
## Anual

```{r}
#| echo: false

df_prf_plot <- prf_sinistros |> 
  mutate(
    mes = month(data_inversa),
    acidentes_fatais = if_else(
      classificacao_acidente == "Com Vítimas Fatais",
      1, 0, missing = 0
    )
  ) |> 
  summarise(
    .by = c(mes, ano, uf),
    acidentes = n(),
    acidentes_fatais = sum(acidentes_fatais),
    feridos = sum(feridos),
    mortes = sum(mortos)
  ) |> 
  arrange(mes, ano) |> 
  collect()

plot_prf_anual <- df_prf_plot |> 
  summarise(.by = ano, across(.fns = sum, acidentes:mortes)) |> 
  filter(ano > 2010) |> 
  rename(
    "Acidentes" = acidentes,
    "Acidentes fatais" = acidentes_fatais,
    "Feridos" = feridos,
    "Mortos" = mortes
  ) |> 
  pivot_longer(-ano) |> 
  ggplot(aes(ano, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste0(name,": ", value)), size = 0.5) +
    scale_x_continuous(breaks = seq(2011, 2023, 1)) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_color_manual(values = paleta) +
    labs(x = "Data", y = NULL)

ggplotly(plot_prf_anual, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```

## Trimestral

```{r}
#| echo: false

plot_prf_tri <- df_prf_plot |> 
  mutate(data = quarter(ym(paste0(ano,"-",mes)), type = "date_last")) |> 
  summarise(.by = data, across(.fns = sum, acidentes:mortes)) |> 
  filter(year(data) > 2010) |> 
  rename(
    "Acidentes" = acidentes,
    "Acidentes fatais" = acidentes_fatais,
    "Feridos" = feridos,
    "Mortos" = mortes
  ) |> 
  pivot_longer(-data) |> 
  ggplot(aes(data, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste0(name,": ", value)), size = 0.5) +
    scale_x_date(date_breaks = "2 years") +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_color_manual(values = paleta) +
    labs(x = "Data", y = NULL)

ggplotly(plot_prf_tri, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```

## Mensal

```{r}
#| echo: false

plot_prf_mensal <- df_prf_plot |> 
  mutate(data = ym(paste0(ano,"-",mes))) |> 
  summarise(.by = data, across(.fns = sum, acidentes:mortes)) |> 
  filter(year(data) > 2010) |> 
  rename(
    "Acidentes" = acidentes,
    "Acidentes fatais" = acidentes_fatais,
    "Feridos" = feridos,
    "Mortos" = mortes
  ) |> 
  pivot_longer(-data) |> 
  ggplot(aes(data, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste0(name,": ", value)), size = 0.5) +
    scale_x_date(date_breaks = "2 years") +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    scale_color_manual(values = paleta) +
    labs(x = "Data", y = NULL)

ggplotly(plot_prf_mensal, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```
:::

## Condutores habilitados (RENACH)

```{r}
#| echo: false

plot_condutores <- tabela_condutores |> 
  ggplot(aes(ano, condutores)) +
    geom_line(color = onsv_palette$blue) +
    geom_point(aes(text = paste("Condutores:",condutores)), color = onsv_palette$blue, size = 0.5) +
    scale_x_continuous(breaks = seq(2011, 2023, 1)) +
    scale_y_continuous(labels = label_comma(big.mark = ".", decimal.mark = ",")) +
    labs(x = "Data", y = "Condutores")

ggplotly(plot_condutores, tooltip = "text") |> 
  layout(yaxis = list(title = list(standoff = 5)))
```
:::

É notavel a diferença entre as condutas de cada atributo com o tempo. Variáveis convencionalmente cumulativas como a frota, a população e o número de condutores habilitados não devem possuir variação, dispondo de um crescimento aproximadamente linear por todo o período de estudo. Todavia, detecta-se que a população se comportou de forma inesperada em alguns anos, o que infere em erros de contagem e estimativa na fonte de dados.

Os dados de rodovias federais flutuam de forma análoga aos óbitos em trânsito, agindo como referências da qualidade da segurança viária nacional de determinado período, com uma sazonalidade pronunciada. Estes dados também mostram claramente como os óbitos são eventos incomuns em comparação com a quantidade de sinistros fatais e totais observados. Porém, enquanto a quantidade de sinistros pode variar intensamente ao longo dos ano, o número de mortes permanece relativamente constante.

O PIB é o atributo com o comportamento mais particular ao longo do tempo em relação às outras variáveis. Foi utilizado o dólar americano em lugar do real brasileiro a fim de observar a oscilação da moeda em um contexto global e revelar a contribuição histórica da economia nacional. Modelos idealizados em @blumenberg2018 e @zhong-xiang2014 utilizam do PIB como um indício da saúde socioeconômica do país e correlata e, consequentemente, uma variável indiretamente correlata a às mortes em trânsito.

### Correlação

O sucesso da modelagem é inteiramente dependente da intensidade e do tipo de relação estatística que as variáveis possuem entre si. Como anteriormente citado, a regressão linear múltipla bem ajustada infere que as preditivas possuem uma correlação linear forte com a preditora, mas um modelo com baixo desempenho não é necessariamente uma evidência de baixa correlação.

Grandezas que variam juntas em uma correlação linear são ditas colineares, e o fenômeno da colinearidade entre variáveis preditivas pode vir a ocasionar sobreajuste ao modelo. Por isso, é necessário avaliar as correlações não lineares, como aponta os correlograma, a partir de método de correlação Spearman, nas três escalas temporais:

::: panel-tabset
## Anual

```{r}
#| echo: false

cor_spearman_anual <- df_total |> 
  drop_na() |> 
  select(-c(quilometragem_10_bilhoes, mortos_por_pop, ano)) |> 
  rename(
    `Óbitos` = mortes,
    Automóveis = automovel,
    Motocicletas = motocicleta,
    `Veículos Totais` = veiculos_total,
    PIB = pib,
    `População` = populacao,
    Acidentes = qnt_acidentes,
    `Acidentes fatais` = qnt_acidentes_fatais,
    Feridos = qnt_feridos,
    Condutores = condutores,
    `Mortes PRF` = qnt_mortos
  ) |> 
  cor(method = "spearman")

ggcorrplot(
  cor_spearman_anual,
  lab_col = "white",
  type = "lower",
  lab = TRUE, 
  hc.order = T,
  lab_size = 3, 
  tl.srt = 60,
  tl.cex = 12, 
  legend.title = "Correlação",
  colors = c(onsv_palette$blue, "white", onsv_palette$red)
)
```

## Trimestral

```{r}
#| echo: false

cor_spearman_trimestral <- dados_mensais |> 
  mutate(data = quarter(data, type = "date_last")) |> 
  summarise(
    .by = data,
    veiculos = last(veiculos),
    automovel = last(automovel),
    motocicleta = last(motocicleta),
    mortes = sum(mortes),
    pib = sum(pib),
    acidentes = sum(acidentes),
    acidentes_fatais = sum(acidentes_fatais),
    feridos = sum(feridos),
    mortes_prf = sum(mortes_prf)
  ) |> 
  select(-data) |> 
  rename(
    `Óbitos` = mortes,
    Automóveis = automovel,
    Motocicletas = motocicleta,
    `Veículos Totais` = veiculos,
    PIB = pib,
    Acidentes = acidentes,
    `Acidentes fatais` = acidentes_fatais,
    Feridos = feridos,
    `Mortes PRF` = mortes_prf
  ) |> 
  cor(method = "spearman")

ggcorrplot(
  cor_spearman_trimestral,
  lab_col = "white",
  type = "lower",
  lab = TRUE, 
  hc.order = T,
  lab_size = 3, 
  tl.srt = 60,
  tl.cex = 12, 
  legend.title = "Correlação",
  colors = c(onsv_palette$blue, "white", onsv_palette$red)
)
```

## Mensal

```{r}
#| echo: false

cor_spearman_mensal <-dados_mensais |> 
  select(-data) |> 
  rename(
    `Óbitos` = mortes,
    Automóveis = automovel,
    Motocicletas = motocicleta,
    `Veículos Totais` = veiculos,
    PIB = pib,
    Acidentes = acidentes,
    `Acidentes fatais` = acidentes_fatais,
    Feridos = feridos,
    `Mortes PRF` = mortes_prf
  ) |> 
  cor(method = "spearman")

ggcorrplot(
  cor_spearman_mensal,
  lab_col = "white",
  type = "lower",
  lab = TRUE, 
  hc.order = T,
  lab_size = 3, 
  tl.srt = 60,
  tl.cex = 12, 
  legend.title = "Correlação",
  colors = c(onsv_palette$blue, "white", onsv_palette$red)
)
```
:::

### Taxas

O diagnóstico da segurança no trânsito de uma uma região em um determinado intervalo de tempo é um dos assuntos mais discutidos no campo da mobilidade segura, visto que as variáveis que influenciam a saúde no trânsito não são um consenso acadêmico absoluto. Este fato fomenta a pesquisa e desenvolvimento de novas metodologias e indicadores específicos para a análise estatística do cenário brasileiro que melhor interpretam os dados disponíveis e representam o fenômeno real da sinistralidade de maneira verossímil. @ferraz2023 disserta sobre a questão da quantificação e qualificação da sinistralidade por meio da determinação de índices utilizando de mortes, população e frota como parâmetros para estabelecer números representativos do nível de segurança do local.

Estes índices são usualmente referidos em função de altas casas decimais para salientar a significância dos valores de cada taxa calculada. As taxas que direcionaram o presente estudo na avaliação da sinistralidade anual foram as de vítimas fatais por 100 mil habitantes e vítimas fatais por 10 mil veículos, como indicado:

```{r}
#| echo: false

plot_taxas <- df_total |> 
  select(ano, veiculos_total, populacao, mortes) |> 
  drop_na() |> 
  mutate(taxa_hab = (mortes/populacao) * 100000,
         taxa_veic = (mortes/veiculos_total) * 10000) |> 
  select(ano, taxa_hab, taxa_veic) |> 
  rename(
    "Óbitos por 100.000 hab" = taxa_hab,
    "Óbitos por 10.000 veículos" = taxa_veic
  ) |> 
  pivot_longer(-ano) |> 
  ggplot(aes(ano, value, color = name)) +
    geom_line() +
    geom_point(aes(text = paste0(name,": ", round(value, 2))), size = 0.5) +
    facet_wrap(vars(name), scales = "free_y") +
    labs(y = "Índices", x = "Data") +
    scale_color_manual(values = paleta)

ggplotly(plot_taxas, tooltip = "text") |> 
  layout(legend = list(title = list(text = "")))
```

As duas taxas anunciam uma diferentes tendência a cerca da sinistralidade e fatalidade no trânsito brasileiro. Enquanto o índice de mortes por veículos oferece uma perspectiva de estabilização no número de vítimas, a taxa por habitantes aparenta corroborar à visão de que as mortes estão inclinadas ao aumento na década atual. Deve-se levar em consideração esta que diferença de comportamente pode resultar do fato de que a frota veicular e a população nacional são variáveis que evoluem em taxas distintas.

### Resultados dos modelos

A avaliação de desempenho de cada modelo foi gerada a partir da necessidade e especificações de cada caso. Visualizações podem ser criadas para todos os modelos a fim de apresentar a proximidade das previsões em relação aos valores reais. Métricas de erros são utilizadas para quantificar a taxa de acertos de cada modelo, notando-se que em modelos com maior disponibilidade de dados (trimestral e mensal) foi efetuada a repartição das amostras de treino e teste, inferindo que as métricas foram validadas a partir das previsões e das amostras de teste. No caso do modelo anual, que possuo um conjunto de dados menor, os dados não foram repartidos e a validação foi feita com o mesmo conjunto de treinamento.

#### Regressão Linear Múltipla

A análise de regressão linear múltipla foi a abordagem mais extensamente utilizada durante a produção do estudo, podendo ser destrinchada a partir das escalas temporais anual, trimestral e mensal. Cada métrica e modelo são extraídos apresentados para avaliação das suas performances, com os resultados segregados por unidade de tempo.

##### Anual

```{r}
#| include: false

metricas <- metric_set(rmse, mae, rsq)

dados_modelo_2023 <- list(
  drop_na(count(rename(rtdeaths, ano = ano_ocorrencia), ano, name = "mortes")),
  summarise(filter(fleetbr, modal == "TOTAL", mes == 7), 
            .by = ano, frota = sum(frota)),
  prf_sinistros |> 
    filter(classificacao_acidente == "Com Vítimas Fatais") |> 
    count(ano, name = "acids_fatais") |> 
    collect(),
  prf_sinistros |> 
    count(ano, name = "acids") |> 
    collect(),
  tabela_condutores
) |> 
  reduce(full_join, by = "ano") |> 
  arrange(ano)

rec_anual_2023 <-
  recipe(x = drop_na(dados_modelo_2023), mortes ~ .) |> 
  remove_role(ano, old_role = "predictor") |> 
  step_normalize(all_numeric_predictors())

modelo_anual_2023 <-
  linear_reg() |> 
  set_engine("lm")
  
wflow_anual_2023 <-
  workflow() |> 
  add_model(modelo_anual_2023) |> 
  add_recipe(rec_anual_2023) |> 
  fit(drop_na(dados_modelo_2023))

pred_anual_2023 <- bind_cols(
  dados_modelo_2023,
  predict(wflow_anual_2023, dados_modelo_2023),
  predict(wflow_anual_2023, dados_modelo_2023, type = "conf_int")
)

metricas_anual <- metricas(data = pred_anual_2023, truth = mortes, estimate = .pred)
```

Para o caso da análise anual, as previsões emitidas são comparadas com as ocorrências reais, enquanto as métricas são baseadas no mesmo conjunto de ajuste do modelo:

::: panel-tabset
## Série

```{r}
#| echo: false

pred_anual_2023 |> 
  select(ano, mortes, .pred, .pred_lower, .pred_upper) |> 
  pivot_longer(
    cols = c(.pred, mortes),
    names_to = "Tipo",
    values_to = "Mortes"
  ) |> 
  mutate(
    Tipo = if_else(Tipo == "mortes", "Óbitos reais", "Óbitos previstos")
  ) |> 
  ggplot(aes(ano, Mortes, color = Tipo)) +
    geom_ribbon(
      aes(ymax = .pred_upper, ymin = .pred_lower),
      fill = "grey",
      color = "grey",
      alpha = 0.25
    ) +
    geom_line(linewidth = 1, alpha = 0.25) +
    geom_point() +
    scale_x_continuous(limits = c(2011,2023), breaks = seq(2011,2023,1)) +
    scale_y_continuous(labels = comma_format(big.mark = ".")) +
    scale_discrete_onsv() + 
    labs(x = NULL, y = NULL)
```

## Previsto x Real

```{r}
#| echo: false

pred_anual_2023 |> 
  select(.pred, mortes, ano) |> 
  drop_na() |> 
  rename(Previsto = .pred, Real = mortes) |> 
  ggplot(aes(x = Real, y = Previsto)) +
  geom_point(shape = 21, size = 1.5, stroke = 1.5, color = onsv_palette$blue) +
  geom_text(aes(label = ano), vjust = 2, size = 3) + 
  geom_abline(
    linewidth = 1, 
    alpha = 0.5, 
    color = onsv_palette$blue, 
    lty = "dashed"
  ) +
  scale_y_continuous(labels = comma_format(big.mark = ".")) + 
  scale_x_continuous(labels = comma_format(big.mark = ".")) +
  coord_obs_pred()
```

## Métricas

```{r}
#| echo: false

metricas_anual |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",")) |> 
  kable(
    caption = "Métricas de Erros", align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

Como é demonstrado pelo amplo intervalo de confiança preditado, o fato do conjunto de dados anuais ser relativamente pequeno confere uma incerteza atribuída à essa abordagem. Para 2023, o modelo prevê 34.631, uma diferença de 1152 vítimas e um aumento de aproximadamente 3,3% em relação ao anterior.

As métricas **RMSE** e **MAE** são melhor aplicadas de forma comparativa entre diferentes ajustes, sendo utilizados para auxiliar na seleção de atributos para o treinamento do modelo. Foi concluído que as melhores variáveis para explicar a ocorrências de óbitos no trânsito para esta categoria de modelo foram a frota total, os acidentes totais e fatais em rodovias federais e os condutores habilitados.

##### Trimestral

Os dados utilizados foram obtidos por meio do agrupamento trimestral dos dados mensais, sendo constituída uma base de dados específica para o ajuste deste modelo de regressão. As métricas e visualizações para avaliação da performance foram as mesmas do modelo anual, porém, a partir deste, todos os próximos modelos são reamostrados em conjuntos de treino e teste para a validação adequada:

```{r}
#| include: false

df_frota_2023 <- fleetbr |> 
  pivot_wider(names_from = modal, values_from = frota) |> 
  mutate(
    data = ym(paste0(ano,"-",mes)),
    automovel = AUTOMOVEL + CAMINHONETE + CAMIONETA + UTILITARIO,
    motocicleta = MOTOCICLETA + CICLOMOTOR + MOTONETA
  ) |> 
  rename(total = TOTAL) |> 
  summarise(
    .by = data,
    veiculos = sum(total),
    automovel = sum(automovel),
    motocicleta = sum(motocicleta)
  )

df_mortes_2023 <- rtdeaths |> 
  mutate(mes = month(data_ocorrencia),
         ano = year(data_ocorrencia),
         data = ym(paste0(ano, "-", mes))) |> 
  count(data, name = "mortes") |> 
  drop_na()

df_pib_2023 <- pib_mensal |> 
  mutate(data = ym(paste0(ano, "-", mes))) |> 
  group_by(data) |> 
  summarise(pib)

df_prf_2023 <- prf_sinistros |> 
  collect() |> 
  mutate(
    acidentes_fatais = if_else(
      classificacao_acidente == "Com Vítimas Fatais", 1, 0, missing = 0
    ),
    mes = month(data_inversa),
    data = ym(paste0(ano, "-", mes))
  ) |> 
  summarise(
    .by = data,
    acidentes = n(),
    acidentes_fatais = sum(acidentes_fatais),
    feridos = sum(feridos),
    mortes_prf = sum(mortos)
  ) |> 
  arrange(data)
  
dados_mensais_2023 <- 
  list(df_frota_2023, df_mortes_2023, df_pib_2023, df_prf_2023) |> 
  reduce(full_join, by = "data") |> 
  arrange(data)

df_trimestre_2023 <- dados_mensais_2023 |>
  mutate(
    trimestre = quarter(data),
    data = quarter(data, type = "date_last")
  ) |> 
  group_by(data, trimestre) |> 
  summarise(
    veiculos = last(veiculos),
    automovel = last(automovel),
    motocicleta = last(motocicleta),
    mortes = sum(mortes),
    pib = sum(pib),
    acidentes = sum(acidentes),
    acidentes_fatais = sum(acidentes_fatais),
    feridos = sum(feridos),
    mortes_prf = sum(mortes_prf)
  ) |> 
  ungroup()

splits_trimestre <- initial_split(drop_na(df_trimestre_2023), prop = 3/4)
train_trimestre <- training(splits_trimestre)
test_trimestre <- testing(splits_trimestre)

rec <- 
  recipe(df_trimestre_2023, mortes ~ .) |> 
  remove_role(c(mortes_prf, trimestre, data), old_role = "predictor") |> 
  step_normalize(all_numeric_predictors())

model <-
  linear_reg() |>
  set_engine("lm")

lm_wflow <-
  workflow() |> 
  add_model(model) |> 
  add_recipe(rec)

lm_wflow_fit <-
  lm_wflow |> 
  fit(train_trimestre)

pred_trimestre_2023 <- bind_cols(
  df_trimestre_2023,
  predict(lm_wflow_fit, df_trimestre_2023),
  predict(lm_wflow_fit, df_trimestre_2023, type = "conf_int")
)

metricas_trimestre <- bind_cols(
  test_trimestre,
  predict(lm_wflow_fit, test_trimestre)
) |> 
  metricas(truth = mortes, estimate = .pred)
```

::: panel-tabset
## Série

```{r}
#| echo: false

pred_trimestre_2023 |> 
  select(data, trimestre, mortes, .pred_lower, .pred_upper, .pred) |> 
  drop_na() |>  
  pivot_longer(cols = c(.pred, mortes),
               names_to = "Tipo",
               values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes, color = Tipo)) +
    geom_ribbon(
      aes(ymax = .pred_upper, ymin = .pred_lower),
      fill = "grey",
      color = "grey",
      alpha = 0.25
    ) +
    geom_line()
```

## Previsto x Real

```{r}
#| echo: false

pred_trimestre_2023 |> 
  select(.pred, mortes) |> 
  drop_na() |> 
  rename(Previsto = .pred, Real = mortes) |> 
  ggplot(aes(x = Real, y = Previsto)) +
  geom_point(shape = 21, size = 1.5, stroke = 1.5, color = onsv_palette$blue) +
  geom_abline(
    linewidth = 1, 
    alpha = 0.5, 
    color = onsv_palette$blue, 
    lty = "dashed"
  ) +
  scale_y_continuous(labels = comma_format(big.mark = ".")) + 
  scale_x_continuous(labels = comma_format(big.mark = ".")) +
  coord_obs_pred()
```

## Métricas

```{r}
#| echo: false

metricas_trimestre |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",")) |> 
  kable(
    caption = "Métricas de Erros", align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

O grafico X espelha visualmente a periodicidade e sazonalidade trimestral da sinistralidade, revelando a existência de épocas de maior risco em trânsito em todo ano, independente da tendência da série temporal de óbitos. Como esperado, a maior disponibilidade de dados resulta em alterações positivas nas métricas de erros em relação à escala temporal anual.

##### Mensal

A escala mensal é a menor unidade temporal abordada para o estudo e permite observar de forma clara a sazonalidade dos sinistros:

```{r}
#| include: false

split_2023 <- initial_split(drop_na(dados_mensais_2023), prop = 0.8)

train_2023 <- training(split_2023)
test_2023 <- testing(split_2023)

rec_mensal_2023 <-
  recipe(train_2023, mortes ~ .) |> 
  remove_role(c(mortes_prf, data), old_role = "predictor") |> 
  step_normalize(all_numeric_predictors())

lm_mensal_2023 <-
  linear_reg() |> 
  set_engine("lm")

lm_wflow_mensal_2023 <-
  workflow() |> 
  add_model(lm_mensal_2023) |> 
  add_recipe(rec_mensal_2023) |> 
  fit(train_2023)

pred_mensal_2023 <-
  bind_cols(
    dados_mensais_2023,
    predict(lm_wflow_mensal_2023, dados_mensais_2023),
    predict(lm_wflow_mensal_2023, dados_mensais_2023, type = "conf_int")
  )

metricas_mensal <- metricas(pred_mensal_2023, truth = mortes, estimate = .pred)
```

::: panel-tabset
## Série

```{r}
#| echo: false

pred_mensal_2023 |> 
  drop_na() |> 
  pivot_longer(cols = c(.pred, mortes),
               names_to = "Tipo",
               values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes, color = Tipo)) +
    geom_ribbon(aes(ymax = .pred_upper, ymin = .pred_lower),
                fill = "grey", color = "grey", alpha = 0.25) +
    geom_line()
```

## Previsto x Real

```{r}
#| echo: false

pred_mensal_2023 |> 
  select(.pred, mortes) |> 
  drop_na() |> 
  rename(Previsto = .pred, Real = mortes) |> 
  ggplot(aes(x = Real, y = Previsto)) +
  geom_point(shape = 21, size = 1.5, stroke = 1.5, color = onsv_palette$blue) +
  geom_abline(
    linewidth = 1, 
    alpha = 0.5, 
    color = onsv_palette$blue, 
    lty = "dashed"
  ) +
  scale_y_continuous(labels = comma_format(big.mark = ".")) + 
  scale_x_continuous(labels = comma_format(big.mark = ".")) +
  coord_obs_pred()
```

## Métricas

```{r}
#| echo: false

metricas_mensal |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",")) |> 
  kable(
    caption = "Métricas de Erros", align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

Uma das características notáveis deste modelo é sua capacidade de descrever observações anômalas ao decorrer dos anos, onde os óbitos ultrapassam os intervalos de confiança estipulados pelo modelo, mesmo que este apresenta com uma alta performance e capacidade preditiva pelas métricas.

As métricas apresentam alterações positivas novamente, associado ao incremento de dados. Estes métricas serão aplicadas para comparar a perfomance e avaliar a utilidade das técnicas contempladas nos modelos posteriores.

#### Regressor Random Forest

O segundo modelo utilizada para a análise de regressão, como anteriormente explicado, foi o Regressor Random Forest, ajustado apenas para o contexto mensal. Esta técnica dispensa a seleção de atributos manual que fora necessária para o caso da regressão linear, já que possui um algoritmo seletor interno. Sendo assim, este modelo é treinado e validado no mesmo conjunto mensal que anteriormente discutido:

```{r}
#| include: false

rf <- 
  rand_forest(
    mode = "regression",
    mtry = 5,
    trees = 5000
  ) |> 
  set_engine("ranger")

rf_wflow <- 
  workflow() |> 
  add_model(rf) |> 
  add_recipe(rec_mensal_2023) |>
  fit(train_2023)

rf_pred <- bind_cols(
  predict(rf_wflow, drop_na(dados_mensais_2023, veiculos)),
  drop_na(dados_mensais_2023, veiculos)
)

metricas_rf <- bind_cols(
  predict(rf_wflow, test_2023),
  test_2023
) |> 
  metricas(truth = mortes, estimate = .pred)
```

::: panel-tabset
## Série

```{r}
#| echo: false

rf_pred |> 
  pivot_longer(c(.pred, mortes), names_to = "Tipo", values_to = "Mortes") |> 
  ggplot(aes(data, Mortes, color = Tipo)) +
    geom_line()
```

## Previsto x Real

```{r}
#| echo: false

rf_pred |> 
  select(.pred, mortes) |> 
  drop_na() |> 
  rename(Previsto = .pred, Real = mortes) |> 
  ggplot(aes(x = Real, y = Previsto)) +
  geom_point(shape = 21, size = 1.5, stroke = 1.5, color = onsv_palette$blue) +
  geom_abline(
    linewidth = 1, 
    alpha = 0.5, 
    color = onsv_palette$blue, 
    lty = "dashed"
  ) +
  scale_y_continuous(labels = comma_format(big.mark = ".")) + 
  scale_x_continuous(labels = comma_format(big.mark = ".")) +
  coord_obs_pred()
```

## Métricas

```{r}
#| echo: false

metricas_rf |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",")) |> 
  kable(
    caption = "Métricas de Erros", align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

O Random Forest se sobressai visualmente no gráfico de valores previstos sobre valores reais, visto que as predições aparentam convergir com mais facilidade ao valor verdadeiro que no modelo anterior. Apesar da incapacidade do algoritmo em gerar intervalos de confiança, o Random Forest raramente estima valores anômalos, apontando que é menos sensível a *outliers* que a regressão linear. Como mencionado na descrição teórica deste algoritmo, este efeito é associado a reamostragem que o modelo faz enquanto está construindo as "árvores" pela técnica *bagging*, reduzindo o enviesamento dos valores discrepantes.

#### SARIMA

```{r}
#| include: false

df_mortes <- rtdeaths |> 
  arrange(data_ocorrencia) |> 
  mutate(data = ym(paste0(ano_ocorrencia, '-', month(data_ocorrencia))),
         .before = 1) |> 
  summarise(.by = data, mortes = n()) |> 
  drop_na()

ts <- ts(df_mortes$mortes, start = c(1996, 1), end = c(2022, 12), frequency = 12)

decomposed <- decompose(ts)
```

Após as análises regressivas, a próxima abordagem estátistica estudada é a análise de séries temporais univariadas, sobretudo iniciada pela condução de experimentos utilizando do método SARIMA. Entretanto, antes da modelagem propriamente dita, algumas evidências podem ser reunidas para indicar a viabilidade destes métodos temporais, como a decomposição da série temporal:

::: panel-tabset
## Série Original

```{r}
#| echo: false

autoplot(
  ts, 
  color = onsv_palette$blue, 
  ylab = "Mortes", xlab = "Data")
```

## Tendência

```{r}
#| echo: false

autoplot(
  decomposed$trend,
  color = onsv_palette$blue,
  ylab = "Mortes", xlab = "Data")
```

## Sazonalidade

```{r}
#| echo: false

autoplot(
  decomposed$seasonal,
  color = onsv_palette$blue,
  ylab = "Mortes", xlab = "Data")
```

## Residual

```{r}
#| echo: false

autoplot(
  decomposed$random,
  color = onsv_palette$blue,
  ylab = "Mortes", xlab = "Data")
```
:::

A série decomposta é observada para determinar se o comportamento das mortes ao longo do tempo é característico de uma série modelável pelo SARIMA. A tendência é um forte indicativo de que há uma média móvel neste fenômeno, mas a grande quantidade de resíduo aponta que não uma sazonalidade tão bem estabelicida e cíclica. Assim, outros métodos para o entendimento da sinistrilidade no tempo são os gráficos ACF (Fator de Autocorrelação) e PACF (Fator de Autocorrelação Parcial):

```{r}
#| echo: false

par(mfrow = c(1, 2))
acf(ts, main = "ACF")
pacf(ts, main = "PACF")
par(mfrow = c(1, 1))
```

Desta maneira, atenta-se que os dados possuem altas correlações com diversos períodos de atraso de forma indireta e indireta. Em especial, a ocorrência de óbitos de um mês aparenta estar profundamente relacionada ao número de óbitos no mesmo mês no ano anterior, visto que há uma alta correlação no *lag* de 12 meses para ambos os gráficos.

Estas análises são úteis para a decisão manual de valores iniciais para os parâmetros do SARIMA. Entretanto, outra forma mais adequada e automatizada de chegar ao ajuste ideal para o modelo é a função de ajuste automático `auto.arima()` do pacote [`forecast`](https://github.com/robjhyndman/forecast) [@hyndman2008], uma implementação do método que busca a melhor combinação de parâmetros baseado nos critérios de seleção de modelo AIC (*Akaike Information Criterion*) e BIC (*Bayesian Information Criterion*).

```{r}
#| include: false

sarima <- auto.arima(
  ts,
  stationary = F,
  seasonal = T
)

sarima_pred <- cbind(fit = sarima$fitted, 
                  forecast = forecast(sarima, h = 12)$mean, 
                  mortes = sarima$x,
                  .pred_lower = forecast(sarima, h = 12)$lower,
                  .pred_upper = forecast(sarima, h = 12)$upper)
sarima_pred <- 
  data.frame(sarima_pred, data = zoo::as.Date(time(sarima_pred))) |> 
  mutate(.pred = coalesce(forecast, fit), .before = 1) |> 
  select(-c(fit, forecast))

metricas_sarima <- metricas(sarima_pred, truth = mortes, estimate = .pred)
```

::: panel-tabset
## Previsão

```{r}
#| echo: false

sarima_pred |> 
  pivot_longer(c(.pred, mortes), names_to = "Tipo", values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", 
                        "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes)) +
    geom_ribbon(aes(ymin = .pred_lower.80., ymax = .pred_upper.80.), fill = "grey80", alpha = 0.5) +
    geom_ribbon(aes(ymin = .pred_lower.95., ymax = .pred_upper.95.), fill = "grey90", alpha = 0.5) +
    geom_line(aes(color = Tipo)) +
    scale_x_date(limits = as_date(c("2011-12-01", NA)))
```

## Métricas

```{r}
#| echo: false

metricas_sarima |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",")) |> 
  kable(
    caption = "Métricas de Erros", align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

Por ser um modelo autoregressivo univariado, as previsões emitidas pelo SARIMA são ruidosas, produzindo amplos intervalos de confiança. Modelos dessa categoria possuem baixa longevidade visto que seu desempenho diminui conforme a distância da previsão ao conjunto original, mas em comparação a modelos determinísticos, não necessitam de outras variáveis para ter resultados e são, em geral, mais simples computacionalmente.

#### Suavização Exponencial

```{r}
#| include: false

ets <- HoltWinters(ts)

ets_pred <- cbind(fit = ets$fitted[, "xhat"], 
                  forecast = forecast(ets, h = 12)$mean, 
                  mortes = ets$x,
                  .pred_lower = forecast(ets, h = 12)$lower,
                  .pred_upper = forecast(ets, h = 12)$upper)
ets_pred <- 
  data.frame(ets_pred, data = zoo::as.Date(time(ets_pred))) |> 
  mutate(.pred = coalesce(forecast, fit), .before = 1) |> 
  select(-c(fit, forecast))

metricas_ets <- metricas(ets_pred, truth = mortes, estimate = .pred)
```

A Suavização Exponencial Holt-Winters, ou Suavização Exponencial Tripla, é o segundo modelo de análise de séries temporais estudado, o qual possui uma abordagem teórica distinta do anterior. Sendo um modelo de suavização, este pretende aproximar uma função que filtre a série temporal original e expresse o comportamento dos dados de forma simplificada.

::: panel-tabset
## Previsão

```{r}
#| echo: false

ets_pred |> 
  pivot_longer(c(.pred, mortes), names_to = "Tipo", values_to = "Mortes") |> 
  mutate(Tipo = if_else(Tipo == "mortes", 
                        "Óbitos reais", "Óbitos previstos")) |> 
  ggplot(aes(data, Mortes)) +
    geom_ribbon(aes(ymin = .pred_lower.80., ymax = .pred_upper.80.), fill = "grey80", alpha = 0.5) +
    geom_ribbon(aes(ymin = .pred_lower.95., ymax = .pred_upper.95.), fill = "grey90", alpha = 0.5) +
    geom_line(aes(color = Tipo)) +
    scale_x_date(limits = as_date(c("2011-12-01", NA)))
```

## Métricas

```{r}
#| echo: false

metricas_ets |> 
  select(-.estimator) |> 
  mutate(
    .metric = case_match(
      .metric,
      "rmse" ~ "RMSE",
      "mae" ~ "MAE",
      "rsq" ~ "R²"
    )
  ) |> 
  rename(Métrica = .metric, Valor = .estimate) |> 
  mutate(Valor = format(Valor, decimal.mark = ",")) |> 
  kable(
    caption = "Métricas de Erros", align = c("l","r"), 
    table.attr = "quarto-disable-processing=true"
  ) |> 
  kable_styling(full_width = F) |> 
  column_spec(1, width = "6cm", bold = T)
```
:::

Modelos de suavização são ainda mais simplistas que modelos ARIMA já que constituem métodos de filtragem espectral convencionais. Usualmente, a literatura destaca que modelos autoregressivos são mais adequados para séries temporais ruidosas, enquanto modelos exponenciais respondem melhor com séries altamente sazonais. Outra possível vantagem da exponenciação é sua priorização de dados mais recentes, dado que este método reduz o peso de cada observação exponencialmente conforme a distância do último valor.

::: callout-note
## referencia

por a literatura
:::

### Comparação de Modelos

Em conformidade com os experimentos, a seleção de um modelo final é feita de forma comparativa, considerando não apenas os índices calculados de métricas de erros, mas também as características e capacidades de cada modelo individualmente. A tabela X demonstra os valores de desempenho dos modelos:

```{r}
#| echo: false

rbind(
  mutate(metricas_anual, modelo = "Regressão Linear", resol = "Anual"),
  mutate(metricas_trimestre, modelo = "Regressão Linear", resol = "Trimestral"),
  mutate(metricas_mensal, modelo = "Regressão Linear", resol = "Mensal"),
  mutate(metricas_rf, modelo = "Random Forest Regressor", resol = "Mensal"),
  mutate(metricas_ets, modelo = "Exponential Smoothing", resol = "Mensal"),
  mutate(metricas_sarima, modelo = "SARIMA", resol = "Mensal")
) |>
  select(-.estimator) |>
  pivot_wider(names_from = .metric, values_from = .estimate) |>
  rename_with(toupper, rmse:rsq) |>
  group_by(resol) |>
  gt(rowname_col = "model") |>
  cols_label(modelo = "Modelo") |>
  fmt_number(decimals = 2,
             sep_mark = ".",
             dec_mark = ",") |>
  tab_header("Métricas de Erros") |>
  tab_options(
    column_labels.background.color = onsv_palette$blue,
    column_labels.font.weight = "bold"
  ) |>
  tab_style(style = cell_text(color = onsv_palette$blue),
            locations = cells_title())
```

As métricas de erros aparentam melhorar conforme diminuem as unidades de tempo, sendo consequência indireta da maior disponibilidade de dados para o treinamento do modelo. Mesmo assim, será perceptível que, por exemplo, um modelo mensal bem ajustado não prevê um ano inteiro melhor que um modelo anual, por efeito da acumulação de erros associados às previsões de cada mês. Como implica a Tabela x, o modelo linear anual aparenta ter resultados mais plausíveis que o mensal, mesmo tendo um desempenho teórico inferior:

```{r}
#| include: false

pred_list <- list(
  rename(
    pred_anual_2023, 
    pred.anual = .pred, 
    upper.anual = .pred_upper, 
    lower.anual = .pred_lower
  ),
  summarise(
    mutate(pred_trimestre_2023, ano = year(data)),
    .by = ano,
    pred.trimestral = sum(.pred),
    upper.trimestral = sum(.pred_upper),
    lower.trimestral = sum(.pred_lower)
  ),
  summarise(
    mutate(pred_mensal_2023, ano = year(data)),
    .by = ano,
    pred.mensal = sum(.pred),
    upper.mensal = sum(.pred_upper),
    lower.mensal = sum(.pred_lower)
  ),
  summarise(
    mutate(rf_pred, ano = year(data)),
    .by = ano,
    pred.rf = sum(.pred)
  ),
  summarise(
    mutate(sarima_pred, ano = year(data)),
    .by = ano,
    pred.sarima = sum(.pred),
    upper.sarima = sum(.pred_upper.80.),
    lower.sarima = sum(.pred_lower.80.)
  ),
  summarise(
    mutate(ets_pred, ano = year(data)),
    .by = ano,
    pred.ets = sum(.pred),
    upper.ets = sum(.pred_upper.80.),
    lower.ets = sum(.pred_lower.80.)
  )
)
```

```{r}
#| echo: false

pred_list |> 
  reduce(left_join, by = "ano") |> 
  select(c(ano, starts_with(c("pred","upper","lower")))) |> 
  last() |> 
  pivot_longer(-ano) |> 
  mutate(
    modelo = str_remove(str_extract(name, "\\..*"), "\\."),
    tipo = str_remove(str_extract(name, "^(.*?)\\."), "\\.")
  ) |> 
  select(-c(ano, name)) |> 
  pivot_wider(values_from = value, names_from = tipo) |> 
  mutate(
    modelo = case_match(
      modelo,
      "anual" ~ "Linear Anual",
      "trimestral" ~ "Linear Trimestral",
      "mensal" ~ "Linear Mensal",
      "rf" ~ "RF Mensal",
      "sarima" ~ "SARIMA Mensal",
      "ets" ~ "ETS Mensal"
    )
  ) |> 
  gt() |> 
  cols_label(
    modelo = "Modelo",
    pred = "Previsão",
    upper = "Máx.",
    lower = "Mín."
  ) |> 
  fmt_number(decimals = 0,
             sep_mark = ".",
             dec_mark = ",") |>
  tab_header("Previsões para 2023") |>
  tab_options(
    column_labels.background.color = onsv_palette$blue,
    column_labels.font.weight = "bold"
  ) |>
  tab_style(style = cell_text(color = onsv_palette$blue),
            locations = cells_title()) |> 
  sub_missing(missing_text = "-") |> 
  tab_footnote(
    footnote = "Algoritmo não produz intervalo de confiança",
    locations = cells_body(columns = modelo,
                           rows = modelo == "RF Mensal"),
    placement = "left"
  ) |> 
  opt_footnote_marks("standard")
```

Nota-se que ambos métodos de análise de séries temporais prevêem uma queda, enquanto os modelos regressivos estipulam que as fatalidades crescem, o que induz a discussção acerca da sinistrilidade fatal como um fenômeno possivelmente incapaz de ser modelado pela abordagem temporal. Na figura X, os resultados de cada modelo foram agrupados e somados por ano para visualização de cada série temporal individualmente:

```{r}
#| echo: false

dodge <- position_dodge(1)

plot_comparison <- pred_list |> 
  reduce(left_join, by = "ano") |> 
  select(c(ano, mortes, starts_with("pred"))) |> 
  pivot_longer(starts_with("pred"), names_to = "tipo", values_to = "pred") |>
  mutate(tipo = case_match(tipo,
                           "pred.anual" ~ "Linear Anual",
                           "pred.trimestral" ~ "Linear Trimestral",
                           "pred.mensal" ~ "Linear Mensal",
                           "pred.rf" ~ "RF Mensal",
                           "pred.sarima" ~ "SARIMA Mensal",
                           "pred.ets" ~ "ETS Mensal")) |> 
  ggplot(aes(ano, mortes)) +
    geom_line(aes(y = pred, color = "Óbitos previstos")) +
    geom_point(aes(y = pred, color = "Óbitos previstos", 
                   text = paste("Previstos:", round(pred)))) +
    geom_line(aes(color = "Óbitos reais")) +
    geom_point(aes(color = "Óbitos reais", 
                   text = paste("Óbitos:", mortes))) +
    scale_color_manual(values = c(onsv_palette$blue, onsv_palette$yellow)) +
    scale_x_continuous(breaks = seq(2011, 2023, 1), limits = c(2011, NA)) +
    theme(axis.text.x = element_text(angle = 90)) +
    facet_wrap(tipo ~ .)
    
ggplotly(plot_comparison, tooltip = "text")
```

```{r}
#| include: false

load(here("data/populacao.rda"))
```

Em questão das taxas anteriormente discutidas para quantificação dos óbitos em relação à população e à frota veicular, novos valores podem ser calculados sobre as previsões a fim de averiguar a evolução destas taxas em função do tempo e tipo de modelo:

::: panel-tabset
## Óbitos por Habitantes

```{r}
#| echo: false

plot_taxa_popul <- pred_list |> 
  append(list(populacao)) |> 
  reduce(left_join, by = "ano") |> 
  select(c(ano, mortes, populacao, starts_with("pred"))) |> 
  pivot_longer(starts_with("pred"), names_to = "tipo", values_to = "pred") |> 
  mutate(taxa_pred = round((pred/populacao) * 100000, 2),
         taxa_real = round((mortes/populacao) * 100000, 2),
         tipo = case_match(tipo,
                           "pred.anual" ~ "Linear Anual",
                           "pred.trimestral" ~ "Linear Trimestral",
                           "pred.mensal" ~ "Linear Mensal",
                           "pred.rf" ~ "RF Mensal",
                           "pred.sarima" ~ "SARIMA Mensal",
                           "pred.ets" ~ "ETS Mensal")) |> 
  ggplot(aes(ano, taxa_real)) +
    geom_line(aes(y = taxa_pred, color = "Óbitos previstos")) +
    geom_point(aes(y = taxa_pred, color = "Óbitos previstos", 
                   text = paste("Taxa prevista:", taxa_pred))) +
    geom_line(aes(color = "Óbitos reais")) +
    geom_point(aes(color = "Óbitos reais", 
                   text = paste("Taxa real:", taxa_real))) +
    scale_color_manual(values = c(onsv_palette$blue, onsv_palette$yellow)) +
    scale_x_continuous(breaks = seq(2011, 2021, 1), limits = c(2011, 2021)) +
    theme(axis.text.x = element_text(angle = 90)) +
    facet_wrap(tipo ~ .)
  
ggplotly(plot_taxa_popul, tooltip = "text") 
```

## Óbitos por Frota Veicular

```{r}
#| echo: false

plot_taxa_frota <- pred_list |> 
  reduce(left_join, by = "ano") |> 
  select(c(ano, mortes, frota, starts_with("pred"))) |> 
  pivot_longer(starts_with("pred"), names_to = "tipo", values_to = "pred") |> 
  mutate(taxa_pred = round((pred/frota) * 10000, 2),
         taxa_real = round((mortes/frota) * 10000, 2),
         tipo = case_match(tipo,
                           "pred.anual" ~ "Linear Anual",
                           "pred.trimestral" ~ "Linear Trimestral",
                           "pred.mensal" ~ "Linear Mensal",
                           "pred.rf" ~ "RF Mensal",
                           "pred.sarima" ~ "SARIMA Mensal",
                           "pred.ets" ~ "ETS Mensal")) |> 
  ggplot(aes(ano, taxa_real)) +
    geom_line(aes(y = taxa_pred, color = "Óbitos previstos")) +
    geom_point(aes(y = taxa_pred, color = "Óbitos previstos", 
                   text = paste("Taxa prevista:", taxa_pred))) +
    geom_line(aes(color = "Óbitos reais")) +
    geom_point(aes(color = "Óbitos reais", 
                   text = paste("Taxa real:", taxa_real))) +
    scale_color_manual(values = c(onsv_palette$blue, onsv_palette$yellow)) +
    scale_x_continuous(breaks = seq(2011, 2021, 1), limits = c(2011, 2021)) +
    theme(axis.text.x = element_text(angle = 90)) +
    facet_wrap(tipo ~ .)

ggplotly(plot_taxa_frota, tooltip = "text")
```
:::

## Conclusão

Os modelos regressivos desenvolvidos antecipam uma tendência ao aumento relativo nas vítimas de sinistros de trânsito em 2023, uma revelação preocupante à presente situação dos sistemas de segurânça viária brasileiros. Em contrapartida, os modelos temporais prevêem uma possível diminuição, provavelmente devido a sensibilidade destes tipos de técnicas à sazonalidade. Por isso, a análise de regressão permanece como a abordagem mais interessante no contexto do fenômeno estudado, tanto pela qualidade da previsão quanto pela capacidade explicativa deste tipo de metodologia. O resultado da análise induz, no mínimo, um estado de alerta sobre o ineficiênia das tecnologias e políticas de controle e mitigação da mortalidade no trânsito.

É fundamental também destacar que as soluções de segurança viária não dependem apenas de atributos da mobilidade urbana. Inúmeros fatores socioeconômicos e de infraestrutura afetam o desempenho da segurança, indiretamente variando com as condições de desenvolvimento e maturidade tecnológica da região em questão. A mobilidade urbana é uma parte integral à toda civilização moderna, o que torna as ações para a segurança viária indispensáveis no processo de planejamento urbano.

O cenário atual da segurança viária brasileira apresenta alguns desafios e deficiências que podem impactar na conquista das metas de redução estabelecidas em âmbito nacional pelo PNATRANS. Os dados previstos mostram um desempenho abaixo do ideal no combate da mortalidade, conferindo uma perspectiva pessimista para o início da nova década no Brasil e, caso este cenário não seja amenizado com antecedência, é improvável a ocorrência de avanços significativos nos objetivos da Segunda Década de Ação pela Segurança no Trânsito.

## Referências
